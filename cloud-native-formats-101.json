{"version":2,"kind":"Notebook","sha256":"320a69176b879e1f6604e5df2ac56d45bf8ba8d843fd9431b24bba295a7631b2","slug":"cloud-native-formats-101","location":"/pangeo/pangeo101/cloud-native-formats-101.ipynb","dependencies":[],"frontmatter":{"title":"Zarr 101","content_includes_title":false,"kernelspec":{"name":"conda-env-earthcode-bids-earthcode-bids-edc_pangeo-py","display_name":"earthcode-bids-earthcode-bids-edc_pangeo","language":"python"},"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"MIT","url":"https://opensource.org/licenses/MIT","name":"MIT License","free":true,"osi":true}},"github":"https://github.com/ESA-EarthCODE/tutorials","subject":"EarthCODE Tutorials","numbering":{"title":{"offset":2}},"source_url":"https://github.com/ESA-EarthCODE/tutorials/blob/main/pangeo/pangeo101/cloud-native-formats-101.ipynb","edit_url":"https://github.com/ESA-EarthCODE/tutorials/edit/main/pangeo/pangeo101/cloud-native-formats-101.ipynb","thumbnail":"/tutorials/build/datasize-35e575a15d75b12953115544777a081f.png","exports":[{"format":"ipynb","filename":"cloud-native-formats-101.ipynb","url":"/tutorials/build/cloud-native-formats-f7b3f50b173ab3a566ea13083563ae9d.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from pystac.extensions.storage import StorageExtension\nfrom datetime import datetime\nfrom pystac_client import Client as pystac_client\nfrom odc.stac import configure_rio, stac_load\n\nimport xarray","key":"xlxDvW9jgT"},{"type":"output","id":"fcDsQcequyQVEeY-p84ni","data":[],"key":"hJfkUHbuKg"}],"key":"piSa5domdW"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Context","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Jn2bDHRjeK"}],"identifier":"context","label":"Context","html_id":"context","implicit":true,"key":"kZf3qqT1qF"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"When dealing with large data files or collections, it’s often impossible to load all the data you want to analyze into a single computer’s RAM at once. This is a situation where the Pangeo ecosystem can help you a lot. Xarray offers the possibility to work lazily on data ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gY3vuZTz1v"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"chunks","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"PPqLJWq0jt"}],"key":"EtwajhJGmL"},{"type":"text","value":", which means pieces of an entire dataset. By reading a dataset in ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"enEJDMWCXq"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"chunks","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"NzagnH0zp5"}],"key":"P5CxSZrdtp"},{"type":"text","value":" we can process our data piece by piece on a single computer and even on a distributed computing cluster using Dask (Cloud or HPC for instance).","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DdFuwtwL8D"}],"key":"N2BLBAXLfi"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"How we will process these ‘chunks’ in a parallel environment will be discussed in ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Hhv1ushtsf"},{"type":"link","url":"./dask_introduction.ipynb","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"dask_introduction","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"cvXmILn7Jc"}],"urlSource":"./dask_introduction.ipynb","key":"iPBDcfgTcO"},{"type":"text","value":". The concept of ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"B3w1kBs7pf"},{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"chunk","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"MTfEaMtM9u"}],"key":"KoAIJbf8er"},{"type":"text","value":" will be explained here.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"V0HxJnocbO"}],"key":"eZTGUh6EPN"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"When we process our data piece by piece, it’s easier to have our input or ouput data also saved in ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"yoUy3AnB2m"},{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"chunks","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"YXJzQwiHLq"}],"key":"tilG4DSwyF"},{"type":"text","value":". ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"lQvVECN7e3"},{"type":"link","url":"https://zarr.readthedocs.io/en/stable/","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Zarr","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"rGO7lprEdB"}],"urlSource":"https://zarr.readthedocs.io/en/stable/","key":"bHmlrNXXlK"},{"type":"text","value":" is the reference library in the Pangeo ecosystem to save our Xarray multidimentional datasets in ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"V0XV9nqunh"},{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"chunks","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"O8K3ljummu"}],"key":"SJSki6SYpg"},{"type":"text","value":".","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"H8MVjLHIYw"}],"key":"YBJjFEHby5"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"link","url":"https://zarr.readthedocs.io/en/stable/","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Zarr","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"h4OCnyWXaw"}],"urlSource":"https://zarr.readthedocs.io/en/stable/","key":"DSk4V359zy"},{"type":"text","value":" is not the only file format which uses ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"zQ9AWJYtGG"},{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"chunk","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"izRs4tKDUv"}],"key":"oMIne6IYmG"},{"type":"text","value":". ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"sHRMCOYqPd"},{"type":"link","url":"https://fsspec.github.io/kerchunk/","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"kerchunk library","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"s6yLpbj0bt"}],"urlSource":"https://fsspec.github.io/kerchunk/","key":"hnYFP9jjgy"},{"type":"text","value":" for example builds a virtual ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Fh3m47Susm"},{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"chunked","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"cFEEMX8Lo2"}],"key":"QCO26nSG8Q"},{"type":"text","value":" dataset based on NetCDF files, and optimizes the access and analysis of large datasets.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Zz2K1rTHcq"}],"key":"E3FjMrOHpe"},{"type":"heading","depth":4,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Data","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"ygft9WaZBX"}],"identifier":"data","label":"Data","html_id":"data","implicit":true,"key":"SrsyVNZ7ox"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"In this workshop, we will be using the ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"yzeTI6hEmr"},{"type":"link","url":"https://opensciencedata.esa.int/products/seasfire-cube/collection","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"SeasFire Data Cube","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"bhp77eTqno"}],"urlSource":"https://opensciencedata.esa.int/products/seasfire-cube/collection","key":"zFBfH2IyFu"},{"type":"text","value":" published to the EarthCODE Open Science Catalog","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"XQFxkuSPm9"}],"key":"O7OdJGyJlJ"},{"type":"heading","depth":5,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Related publications","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"JSBMITfwya"}],"identifier":"related-publications","label":"Related publications","html_id":"related-publications","implicit":true,"key":"g4t0YLeiT4"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"paragraph","children":[{"type":"emphasis","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Alonso, Lazaro, Gans, Fabian, Karasante, Ilektra, Ahuja, Akanksha, Prapas, Ioannis, Kondylatos, Spyros, Papoutsis, Ioannis, Panagiotou, Eleannna, Michail, Dimitrios, Cremer, Felix, Weber, Ulrich, & Carvalhais, Nuno. (2022). SeasFire Cube: A Global Dataset for Seasonal Fire Modeling in the Earth System (0.4) [Data set]. Zenodo. ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"ZCovXSyHOr"},{"type":"cite","identifier":"alonso-2024","label":"alonso-2024","kind":"narrative","position":{"start":{"line":16,"column":331},"end":{"line":16,"column":343}},"children":[{"type":"text","value":"Alonso ","key":"l4cFsgVsl3"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"xURUpOEWXx"}],"key":"zF8TkvCTQz"},{"type":"text","value":" (2024)","key":"EPSIcrdKXw"}],"enumerator":"1","key":"GhERCEe9OO"},{"type":"text","value":". The same dataset can also be downloaded from Zenodo: ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"QXfBHCBHzt"},{"type":"link","url":"https://zenodo.org/records/13834057","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"https://​zenodo​.org​/records​/13834057","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"T0le27X0RA"}],"urlSource":"https://zenodo.org/records/13834057","key":"xKbJ7aybar"}],"key":"aqLPuYkd4D"}],"key":"U520lcklKa"}],"key":"rPNJCkMYAc"}],"key":"QaocezAoVw"}],"key":"WBQruGhxSC"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"http_url = \"https://s3.waw4-1.cloudferro.com/EarthCODE/OSCAssets/seasfire/seasfire_v0.4.zarr/\"\n\nds = xarray.open_dataset(\n\thttp_url,\n\tengine='zarr',\n    chunks={},\n\tconsolidated=True\n\t# storage_options = {'token': 'anon'}\n)\nds","key":"mWYOvfwtLn"},{"type":"output","id":"1VcPwISOg6BCQR2RlbJZ_","data":[{"output_type":"execute_result","execution_count":3,"metadata":{},"data":{"text/html":{"content_type":"text/html","hash":"697ebc9ec2b48d8438c533a8656183a8","path":"/tutorials/build/697ebc9ec2b48d8438c533a8656183a8.html"},"text/plain":{"content":"<xarray.Dataset> Size: 164GB\nDimensions:                         (latitude: 720, longitude: 1440, time: 966)\nCoordinates:\n  * latitude                        (latitude) float64 6kB 89.88 ... -89.88\n  * longitude                       (longitude) float64 12kB -179.9 ... 179.9\n  * time                            (time) datetime64[ns] 8kB 2001-01-01 ... ...\nData variables: (12/59)\n    area                            (latitude, longitude) float32 4MB dask.array<chunksize=(180, 360), meta=np.ndarray>\n    biomes                          (latitude, longitude) float32 4MB dask.array<chunksize=(180, 360), meta=np.ndarray>\n    cams_co2fire                    (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    cams_frpfire                    (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    drought_code_max                (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    drought_code_mean               (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    ...                              ...\n    t2m_max                         (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    t2m_mean                        (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    t2m_min                         (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    tp                              (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    vpd                             (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    ws10                            (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\nAttributes:\n    crs:          EPSG:4326\n    description:  The SeasFire Cube is a scientific datacube for seasonal fir...\n    title:        SeasFire Cube: A Global Dataset for Seasonal Fire Modeling ...","content_type":"text/plain"}}}],"key":"dh6NsKnEdU"}],"key":"lwmQrERpSx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"total_size_GB = sum(var.nbytes for var in ds.data_vars.values()) / 1e9  # B to GB\nprint(f\"Total size: {total_size_GB:.2f} GB\")","key":"EoTT1gofDN"},{"type":"output","id":"g4vw4YAbJrFa3X_F1wyQj","data":[{"name":"stdout","output_type":"stream","text":"Total size: 164.27 GB\n"}],"key":"x2TvgiqJJl"}],"key":"PojSzO4inH"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"What is a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GvrhoNr2WT"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"chunk","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GZ8ezq5Bk1"}],"key":"ULVHtBKeTH"}],"identifier":"what-is-a-chunk","label":"What is a chunk","html_id":"what-is-a-chunk","implicit":true,"key":"hM1VD740WT"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"If you look carefully at our dataset, each Data Variable is a ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"XWay4k7q3D"},{"type":"inlineCode","value":"ndarray","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Ju2sy3S8BX"},{"type":"text","value":" (or ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"O4P0s0rVrJ"},{"type":"inlineCode","value":"dask.array","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"dbFSbvUxpX"},{"type":"text","value":" if you have a dask client instantiated) with a chunk size of ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"IiLiX5Mbbi"},{"type":"inlineCode","value":"(966, 180, 360)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"EBH0yIriUK"},{"type":"text","value":". So basically accessing one data variable would load arrays of dimensions ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"oTqIfFvk3U"},{"type":"inlineCode","value":"(966, 180, 360)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"K7oDPueXXe"},{"type":"text","value":" into the computer’s RAM. You can see this information and more details by clicking the icon as indicated in the image below.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"mqs9TdZdX1"}],"key":"lJDUAcYOSo"},{"type":"image","url":"/tutorials/build/datasize-35e575a15d75b12953115544777a081f.png","alt":"Dask.array","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"WiIiGPuGLa","urlSource":"../static/datasize.png"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"When you need to analyze large files, a computer’s memory may not be sufficient anymore.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"FUekeuccrK"}],"key":"rEQ0b7VNIo"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"This is where understanding and using chunking correctly comes into play.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"BCQH44ETwy"}],"key":"cEeS0C1Bmd"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Chunking","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"ZMtXepiTE6"}],"key":"YzSpxTkYlh"},{"type":"text","value":" is splitting a dataset into small pieces.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"CbhV1B4Ppe"}],"key":"YmJpw4qauD"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Original dataset is in one piece,","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"UlTqfRgnA6"},{"type":"break","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"HpRKpDN2wi"},{"type":"image","url":"/tutorials/build/notchunked-7ce66751a1a56aa43373241e32615781.png","alt":"Dask.array","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"uLE2NxPRBf","urlSource":"../static/notchunked.png"}],"key":"OjIZCKcRKM"},{"type":"paragraph","position":{"start":{"line":16,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"and we split it into several smaller pieces.","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"IdfQfXPORf"},{"type":"break","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"TjbYR5vnVC"},{"type":"image","url":"/tutorials/build/chunked-56cec5d946b4b97d08ac2165ac882422.png","alt":"Dask.array","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"cHnvOo6KFP","urlSource":"../static/chunked.png"}],"key":"czP0fFoZEI"},{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"We split it into pieces so that we can process our data block by block or ","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"GVpu2qLR3G"},{"type":"strong","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"chunk","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"J4bbOtXu8I"}],"key":"x1qf4W3d9t"},{"type":"text","value":" by ","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"aXMi1EkGu1"},{"type":"strong","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"chunk","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"r7excFTBJQ"}],"key":"s2TVNbjTc9"},{"type":"text","value":".","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"lpXhaxAKvO"}],"key":"fxV3ncjkXX"},{"type":"paragraph","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"In our case, the data is already chunked, in a cloud-native format ready for analysis and usage - in ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"wdJBvfdkFa"},{"type":"strong","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"zarr format","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"ciUdkbHD32"}],"key":"XYk5r1gWLI"}],"key":"SEKS4lUWV5"}],"key":"JRqO24bMLe"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Zarr","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wCxGRwW1NS"}],"identifier":"zarr","label":"Zarr","html_id":"zarr","implicit":true,"key":"IKL46hEoDk"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Zarr’s main characteristics are the following:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ezu3LjeCST"}],"key":"S0BpsMiz2r"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Every chunk of a Zarr dataset is stored as a single file","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"zzQMSNo0HH"}],"key":"r9GkGlN87z"}],"key":"dzFeVIgGD6"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Each Data array in a Zarr dataset has a two unique files containing metadata:","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"tB8T9lzoru"}],"key":"eTer3r2d8R"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":7,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":".zattrs for dataset or dataarray general metadatas","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"gw2AgCpgB5"}],"key":"QfFJDsDTWb"}],"key":"JNhIblt50i"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":".zarray indicating how the dataarray is chunked, and where to find them on disk or other storage.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"XECp0wk3vE"}],"key":"yRDR2Ndbw2"}],"key":"dfg4CjhoMS"}],"key":"dUvzC7iPoO"}],"key":"EOdDPPLsxa"}],"key":"Cv3XT3ZZTU"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Zarr can be considered as an Analysis Ready, cloud optimized data (ARCO) file format!","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"wgugLWZkff"}],"key":"iFJ9YzTFp2"}],"key":"rW1L3bGTnq"}],"key":"IXX8FWtJJw"},"references":{"cite":{"order":["alonso-2024"],"data":{"alonso-2024":{"label":"alonso-2024","enumerator":"1","doi":"10.5281/ZENODO.13834057","html":"Alonso, L., Gans, F., Karasante, I., Ahuja, A., Prapas, I., Kondylatos, S., Papoutsis, I., Panagiotou, E., Mihail, D., Cremer, F., Weber, U., & Carvalhais, N. (2024). <i>SeasFire Cube: A Global Dataset for Seasonal Fire Modeling in the Earth System</i>. Zenodo. <a target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.5281/ZENODO.13834057\">10.5281/ZENODO.13834057</a>","url":"https://doi.org/10.5281/ZENODO.13834057"}}}},"footer":{"navigation":{"prev":{"title":"Xarray 101","url":"/xarray101","group":"EarthCODE Tutorials"},"next":{"title":"Dask 101","url":"/dask101","group":"EarthCODE Tutorials"}}},"domain":"http://localhost:3000"}