{"version":2,"kind":"Notebook","sha256":"320a69176b879e1f6604e5df2ac56d45bf8ba8d843fd9431b24bba295a7631b2","slug":"cloud-native-formats-101","location":"/pangeo/pangeo101/cloud-native-formats-101.ipynb","dependencies":[],"frontmatter":{"title":"Zarr 101","content_includes_title":false,"kernelspec":{"name":"conda-env-earthcode-bids-earthcode-bids-edc_pangeo-py","display_name":"earthcode-bids-earthcode-bids-edc_pangeo","language":"python"},"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"MIT","url":"https://opensource.org/licenses/MIT","name":"MIT License","free":true,"osi":true}},"github":"https://github.com/ESA-EarthCODE/tutorials","subject":"EarthCODE Tutorials","numbering":{"title":{"offset":2}},"source_url":"https://github.com/ESA-EarthCODE/tutorials/blob/main/pangeo/pangeo101/cloud-native-formats-101.ipynb","edit_url":"https://github.com/ESA-EarthCODE/tutorials/edit/main/pangeo/pangeo101/cloud-native-formats-101.ipynb","thumbnail":"/tutorials/build/datasize-c9d51bd0abffffa910c5af7fe902f0b9.png","exports":[{"format":"ipynb","filename":"cloud-native-formats-101.ipynb","url":"/tutorials/build/cloud-native-formats-516c5cd16843b4618c035735358c2c20.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from pystac.extensions.storage import StorageExtension\nfrom datetime import datetime\nfrom pystac_client import Client as pystac_client\nfrom odc.stac import configure_rio, stac_load\n\nimport xarray","key":"ngAWNqu4Z1"},{"type":"output","id":"OogwpmAv7TG3oeceSs7aA","data":[],"key":"hCPkCjigvR"}],"key":"mZO8nr9y6V"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Context","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"AnGS8IzeRa"}],"identifier":"context","label":"Context","html_id":"context","implicit":true,"key":"hHHMzJ6iF8"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"When dealing with large data files or collections, it’s often impossible to load all the data you want to analyze into a single computer’s RAM at once. This is a situation where the Pangeo ecosystem can help you a lot. Xarray offers the possibility to work lazily on data ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"tGDUYfzclq"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"chunks","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ZaWE0Igo5g"}],"key":"XeWShjXvVy"},{"type":"text","value":", which means pieces of an entire dataset. By reading a dataset in ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"H5oOAqmgoJ"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"chunks","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gdv6sBy91e"}],"key":"gT0Ks3cFv6"},{"type":"text","value":" we can process our data piece by piece on a single computer and even on a distributed computing cluster using Dask (Cloud or HPC for instance).","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"n0vYiYjtNq"}],"key":"CCGLXDOAdl"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"How we will process these ‘chunks’ in a parallel environment will be discussed in ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"rumKrypsep"},{"type":"link","url":"./dask_introduction.ipynb","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"dask_introduction","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"j8pcS0oKUi"}],"urlSource":"./dask_introduction.ipynb","key":"YqIAKuuLOe"},{"type":"text","value":". The concept of ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"nDMWA7xZCK"},{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"chunk","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"EeDIV9j6KT"}],"key":"VWXp8oIYa9"},{"type":"text","value":" will be explained here.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"E3rfd3PU37"}],"key":"US4aPuQiRP"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"When we process our data piece by piece, it’s easier to have our input or ouput data also saved in ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"pJ51qUy23O"},{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"chunks","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"adDHpRh9tP"}],"key":"CylMIrxidc"},{"type":"text","value":". ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"yUCkuioO4Y"},{"type":"link","url":"https://zarr.readthedocs.io/en/stable/","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Zarr","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"WzrDKdruir"}],"urlSource":"https://zarr.readthedocs.io/en/stable/","key":"pRXomijLfB"},{"type":"text","value":" is the reference library in the Pangeo ecosystem to save our Xarray multidimentional datasets in ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"fJtiybzzfG"},{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"chunks","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"YYHi3UR9VC"}],"key":"G7yxn4Hsz3"},{"type":"text","value":".","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"TZoZSXtlqW"}],"key":"jkWQTH8uUm"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"link","url":"https://zarr.readthedocs.io/en/stable/","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Zarr","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"R3eXB3oK7d"}],"urlSource":"https://zarr.readthedocs.io/en/stable/","key":"b9X7xpWJqq"},{"type":"text","value":" is not the only file format which uses ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"gZ2rx2i7MX"},{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"chunk","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"MiNVWEv9lM"}],"key":"TvA0OUcMN8"},{"type":"text","value":". ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"x1lPW6O1oA"},{"type":"link","url":"https://fsspec.github.io/kerchunk/","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"kerchunk library","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"t59io07rXB"}],"urlSource":"https://fsspec.github.io/kerchunk/","key":"u0jYPXauF1"},{"type":"text","value":" for example builds a virtual ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"IrUnOStxxi"},{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"chunked","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"ujM902BBgY"}],"key":"GcUtWZ2gZF"},{"type":"text","value":" dataset based on NetCDF files, and optimizes the access and analysis of large datasets.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"u1uU4d4lRj"}],"key":"heTJ2Nzxoz"},{"type":"heading","depth":4,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Data","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"rGnfnEe0RJ"}],"identifier":"data","label":"Data","html_id":"data","implicit":true,"key":"OJPTEHvs3j"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"In this workshop, we will be using the ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"qJzB0DA13O"},{"type":"link","url":"https://opensciencedata.esa.int/products/seasfire-cube/collection","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"SeasFire Data Cube","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"V9dVgwuwkl"}],"urlSource":"https://opensciencedata.esa.int/products/seasfire-cube/collection","key":"KeZL4y01MA"},{"type":"text","value":" published to the EarthCODE Open Science Catalog","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"xAfLNQWz4i"}],"key":"sw4gb8UeKA"},{"type":"heading","depth":5,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Related publications","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"F4DQsZ6128"}],"identifier":"related-publications","label":"Related publications","html_id":"related-publications","implicit":true,"key":"PAD1urHVqY"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"paragraph","children":[{"type":"emphasis","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Alonso, Lazaro, Gans, Fabian, Karasante, Ilektra, Ahuja, Akanksha, Prapas, Ioannis, Kondylatos, Spyros, Papoutsis, Ioannis, Panagiotou, Eleannna, Michail, Dimitrios, Cremer, Felix, Weber, Ulrich, & Carvalhais, Nuno. (2022). SeasFire Cube: A Global Dataset for Seasonal Fire Modeling in the Earth System (0.4) [Data set]. Zenodo. ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"nOdETYaNcP"},{"type":"cite","identifier":"alonso-2024","label":"alonso-2024","kind":"narrative","position":{"start":{"line":16,"column":331},"end":{"line":16,"column":343}},"children":[{"type":"text","value":"Alonso ","key":"zuQJdgYbqH"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"BrsHE5uxny"}],"key":"xjkUwGYG4Z"},{"type":"text","value":" (2024)","key":"r5SWumonvd"}],"enumerator":"1","key":"wMVgxNUzfr"},{"type":"text","value":". The same dataset can also be downloaded from Zenodo: ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"XnQdtnU4zk"},{"type":"link","url":"https://zenodo.org/records/13834057","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"https://​zenodo​.org​/records​/13834057","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"mjy8tXQ6lI"}],"urlSource":"https://zenodo.org/records/13834057","key":"rKoQYr8Jzt"}],"key":"BPlgTAM6n0"}],"key":"UlvNS742AQ"}],"key":"K9wjwLPtfz"}],"key":"ECsWJioKBf"}],"key":"b1nkxmm38G"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"http_url = \"https://s3.waw4-1.cloudferro.com/EarthCODE/OSCAssets/seasfire/seasfire_v0.4.zarr/\"\n\nds = xarray.open_dataset(\n\thttp_url,\n\tengine='zarr',\n    chunks={},\n\tconsolidated=True\n\t# storage_options = {'token': 'anon'}\n)\nds","key":"LqR06nxXLT"},{"type":"output","id":"d9qYKMOzIjTi6DLgnp3DF","data":[{"output_type":"execute_result","execution_count":3,"metadata":{},"data":{"text/html":{"content_type":"text/html","hash":"697ebc9ec2b48d8438c533a8656183a8","path":"/tutorials/build/697ebc9ec2b48d8438c533a8656183a8.html"},"text/plain":{"content":"<xarray.Dataset> Size: 164GB\nDimensions:                         (latitude: 720, longitude: 1440, time: 966)\nCoordinates:\n  * latitude                        (latitude) float64 6kB 89.88 ... -89.88\n  * longitude                       (longitude) float64 12kB -179.9 ... 179.9\n  * time                            (time) datetime64[ns] 8kB 2001-01-01 ... ...\nData variables: (12/59)\n    area                            (latitude, longitude) float32 4MB dask.array<chunksize=(180, 360), meta=np.ndarray>\n    biomes                          (latitude, longitude) float32 4MB dask.array<chunksize=(180, 360), meta=np.ndarray>\n    cams_co2fire                    (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    cams_frpfire                    (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    drought_code_max                (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    drought_code_mean               (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    ...                              ...\n    t2m_max                         (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    t2m_mean                        (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    t2m_min                         (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    tp                              (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    vpd                             (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\n    ws10                            (time, latitude, longitude) float32 4GB dask.array<chunksize=(966, 180, 360), meta=np.ndarray>\nAttributes:\n    crs:          EPSG:4326\n    description:  The SeasFire Cube is a scientific datacube for seasonal fir...\n    title:        SeasFire Cube: A Global Dataset for Seasonal Fire Modeling ...","content_type":"text/plain"}}}],"key":"lMoLiwh9c3"}],"key":"vUWEyx7xt5"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"total_size_GB = sum(var.nbytes for var in ds.data_vars.values()) / 1e9  # B to GB\nprint(f\"Total size: {total_size_GB:.2f} GB\")","key":"DuVRocvCQV"},{"type":"output","id":"Safr5MyUB_5_HgQSFbOKx","data":[{"name":"stdout","output_type":"stream","text":"Total size: 164.27 GB\n"}],"key":"piQHnJzMTl"}],"key":"ToEuVMizX6"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"What is a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"R9vhkdkxI4"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"chunk","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PX6QOGl14j"}],"key":"q4DAnW5Yut"}],"identifier":"what-is-a-chunk","label":"What is a chunk","html_id":"what-is-a-chunk","implicit":true,"key":"DPEg05AB1M"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"If you look carefully at our dataset, each Data Variable is a ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"X56mVc1sWA"},{"type":"inlineCode","value":"ndarray","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"VDAdBbGwmx"},{"type":"text","value":" (or ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Eqwlf7bXLd"},{"type":"inlineCode","value":"dask.array","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"JqxnAhzTIe"},{"type":"text","value":" if you have a dask client instantiated) with a chunk size of ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"eTi1EMIUA4"},{"type":"inlineCode","value":"(966, 180, 360)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"MwcbnZBJSv"},{"type":"text","value":". So basically accessing one data variable would load arrays of dimensions ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"SRhh3KCbqg"},{"type":"inlineCode","value":"(966, 180, 360)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Te3wmJdegg"},{"type":"text","value":" into the computer’s RAM. You can see this information and more details by clicking the icon as indicated in the image below.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"lRI9dcEhht"}],"key":"LHeGMaGqId"},{"type":"image","url":"/tutorials/build/datasize-c9d51bd0abffffa910c5af7fe902f0b9.png","alt":"Dask.array","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Vb7BkwMgdR","urlSource":"../static/datasize.png"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"When you need to analyze large files, a computer’s memory may not be sufficient anymore.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"u9cjuUeqJO"}],"key":"rXEcWlUFy7"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"This is where understanding and using chunking correctly comes into play.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"THoQx1ZobS"}],"key":"yF7BM4y0N0"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Chunking","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"Fmg3aNFOtu"}],"key":"S7jX4ylaXg"},{"type":"text","value":" is splitting a dataset into small pieces.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"GFzwGaVasc"}],"key":"aqEEyn0Ggz"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Original dataset is in one piece,","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"Hb1eaMFfEf"},{"type":"break","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"UtEnwtCsag"},{"type":"image","url":"/tutorials/build/notchunked-b446cf2d8b59ec95a3a0faa9e165a505.png","alt":"Dask.array","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"IjXjQhbihl","urlSource":"../static/notchunked.png"}],"key":"idkd9ORx7u"},{"type":"paragraph","position":{"start":{"line":16,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"and we split it into several smaller pieces.","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"ZtnW0iKtjt"},{"type":"break","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"w7Y7OUi7g8"},{"type":"image","url":"/tutorials/build/chunked-3acce574c2c04249f5cd62802fd69a38.png","alt":"Dask.array","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"Lnipcf7CvA","urlSource":"../static/chunked.png"}],"key":"zczLste3Ri"},{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"We split it into pieces so that we can process our data block by block or ","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"ciIJpSqDS0"},{"type":"strong","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"chunk","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"r31iuKXTfs"}],"key":"KeEDVIkTuF"},{"type":"text","value":" by ","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"fxQoPgkKSH"},{"type":"strong","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"chunk","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"HN1cjFr9RN"}],"key":"tNSl8hjqEK"},{"type":"text","value":".","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"xRod2JIlvm"}],"key":"RgNEFeBYwO"},{"type":"paragraph","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"In our case, the data is already chunked, in a cloud-native format ready for analysis and usage - in ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"hPMIgkwi14"},{"type":"strong","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"zarr format","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"gN2GUMAuBZ"}],"key":"IZiej5MBhD"}],"key":"SWPSa4AYGV"}],"key":"a9kVxSKkh1"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Zarr","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wfpqa10f36"}],"identifier":"zarr","label":"Zarr","html_id":"zarr","implicit":true,"key":"svLI080LEF"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Zarr’s main characteristics are the following:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"P8plWDm7kp"}],"key":"ZHJ2fgeeib"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Every chunk of a Zarr dataset is stored as a single file","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"BKiMMi5WtD"}],"key":"Xvr5tKmTnU"}],"key":"LDxDaT2tKB"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Each Data array in a Zarr dataset has a two unique files containing metadata:","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"E2oLStSmGk"}],"key":"mNo35utwLT"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":7,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":".zattrs for dataset or dataarray general metadatas","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"wPOoszvLPj"}],"key":"l9qivGbLvF"}],"key":"wVPDLrg3i6"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":".zarray indicating how the dataarray is chunked, and where to find them on disk or other storage.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"jST8WjYG4C"}],"key":"Plv4EuSqKa"}],"key":"lryWgbp44U"}],"key":"ZbxgpOIau8"}],"key":"JSZBFoRtuC"}],"key":"uwKzzyb4aZ"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Zarr can be considered as an Analysis Ready, cloud optimized data (ARCO) file format!","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"UCyJOw0AxF"}],"key":"OyllT522tu"}],"key":"Ead05bxAqu"}],"key":"GxEhy15Xue"},"references":{"cite":{"order":["alonso-2024"],"data":{"alonso-2024":{"label":"alonso-2024","enumerator":"1","doi":"10.5281/ZENODO.13834057","html":"Alonso, L., Gans, F., Karasante, I., Ahuja, A., Prapas, I., Kondylatos, S., Papoutsis, I., Panagiotou, E., Mihail, D., Cremer, F., Weber, U., & Carvalhais, N. (2024). <i>SeasFire Cube: A Global Dataset for Seasonal Fire Modeling in the Earth System</i>. Zenodo. <a target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.5281/ZENODO.13834057\">10.5281/ZENODO.13834057</a>","url":"https://doi.org/10.5281/ZENODO.13834057"}}}},"footer":{"navigation":{"prev":{"title":"Xarray 101","url":"/xarray101","group":"EarthCODE Tutorials"},"next":{"title":"Dask 101","url":"/dask101","group":"EarthCODE Tutorials"}}},"domain":"http://localhost:3000"}