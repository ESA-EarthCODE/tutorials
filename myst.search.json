{"version":"1","records":[{"hierarchy":{"lvl1":"Git Clerk"},"type":"lvl1","url":"/git-clerk-example","position":0},{"hierarchy":{"lvl1":"Git Clerk"},"content":"A tutorial on how to use Git Clerk, A visual interface to the Open Science Catalog, to upload data.\n\nFirst log in to  \n\nhttps://​workspace​.earthcode​.eox​.at/\n\nAccept the required permissions, so that git-clerk can open PR requests from your github account in the OSC repository.\n\nClick on the Open Science Catalog Editor.","type":"content","url":"/git-clerk-example","position":1},{"hierarchy":{"lvl1":"Open Science Catalog"},"type":"lvl1","url":"/index-2","position":0},{"hierarchy":{"lvl1":"Open Science Catalog"},"content":"The \n\nOpen Science Catalog (OSC) is a key component of the ESA EO Open Science framework. It is a publicly available web-based application designed to provide easy access to scientific resources including geoscience products, workflows, experiments and documentation from activities and projects funded by ESA under the EO Programme.\n\nThere are three ways to add information to the OSC:","type":"content","url":"/index-2","position":1},{"hierarchy":{"lvl1":"Open Science Catalog","lvl2":"1: Using a Visual GUI"},"type":"lvl2","url":"/index-2#id-1-using-a-visual-gui","position":2},{"hierarchy":{"lvl1":"Open Science Catalog","lvl2":"1: Using a Visual GUI"},"content":"Git Clerk - A guide for using the Git Clerk tool which is a user interface for automatically creating product entries and creating a Pull Request in the OSC GitHub Repo.","type":"content","url":"/index-2#id-1-using-a-visual-gui","position":3},{"hierarchy":{"lvl1":"Open Science Catalog","lvl2":"2: Manually opening a PR"},"type":"lvl2","url":"/index-2#id-2-manually-opening-a-pr","position":4},{"hierarchy":{"lvl1":"Open Science Catalog","lvl2":"2: Manually opening a PR"},"content":"Directly editing the json files - A guide for manually creating Product entries. Requires knowledge of git.\n\nGenerating OSC files using pystac - A guide for creating Product entries using pystac. Requires knowledge of git and Python.","type":"content","url":"/index-2#id-2-manually-opening-a-pr","position":5},{"hierarchy":{"lvl1":"Open Science Catalog","lvl2":"3: Using one of the platform tools"},"type":"lvl2","url":"/index-2#id-3-using-one-of-the-platform-tools","position":6},{"hierarchy":{"lvl1":"Open Science Catalog","lvl2":"3: Using one of the platform tools"},"content":"DeepCode - An example using DeepCode: a library for automatically generating product entries for DeepESDL datasets.","type":"content","url":"/index-2#id-3-using-one-of-the-platform-tools","position":7},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)"},"type":"lvl1","url":"/osc-pr-manual","position":0},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)"},"content":"The \n\nOpen Science Catalog (OSC) is a key component of the ESA EO Open Science framework. It is a publicly available web-based application designed to provide easy access to scientific resources including geoscience products, workflows, experiments and documentation from activities and projects funded by ESA under the EO Programme.\n\nThe Open Science Catalog is built on the Spatio Temporal Asset Catalog (STAC), which is a standardised format for describing geospatial data. Throught the open source STAC browser, the catalog allows users to browse and explore interlinked elements such as themes, variables, EO missions, projects, products, workflows, and experiments, all described using STAC-compliant JSON files. This schema ensures that these can be easily reused by other scientists and automated workflowss and correclty displayed in the web browser. Data, workflows, and experiments are documented in the catalogue primarily through enriched metadata and direct links to the corresponding research outcomes. The physical location of these resources is typically indicated via the Project Results Repository or other secure external repositories. Further details on the OSC format can be found \n\nhere.","type":"content","url":"/osc-pr-manual","position":1},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)","lvl2":"Adding information to the OSC"},"type":"lvl2","url":"/osc-pr-manual#adding-information-to-the-osc","position":2},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)","lvl2":"Adding information to the OSC"},"content":"There are three ways to add information to the OSC.\n\nManually opening a pull request (this tutorial)\n\nUsing the GUI editor.\n\nUsing one of the platform specific tools\n\nThis notebook describes how you can add information to the OSC by manually creating and editting json files that describe STAC Collections and Catalogs. The steps to add information in this way are:\n\nFork the repository\n\nAdd the information about project/product/workflow/variables in STAC json format.\n\nOpen a PR to merge the new information into the OSC.\n\nIn general most of the information that you need, is already in your data or project documentation, so you will NOT need to generate anything new. All information that you provide will be automatically validated and manually verified by an EarthCODE team member. Therefore, you can use the automatic validation from the CI to make the appropriate changes to the format or information you provide.","type":"content","url":"/osc-pr-manual#adding-information-to-the-osc","position":3},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)","lvl3":"1. Forking the repository","lvl2":"Adding information to the OSC"},"type":"lvl3","url":"/osc-pr-manual#id-1-forking-the-repository","position":4},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)","lvl3":"1. Forking the repository","lvl2":"Adding information to the OSC"},"content":"Since the OSC metadata is fully hosted on GitHub. Use your personal GitHub account to cotnribute to the catalog. If you do not have an account, you need to setup a new GitHub account: \n\nhttps://​docs​.github​.com​/en​/get​-started​/start​-your​-journey​/creating​-an​-account​-on​-github.\n\nTo contribute your research outputs, you need to create valid STAC objects and commit them to the \n\nopen-science-catalog-metadata repository on GitHub.\nThe first step in this process is to fork the open-science-catalog-metadata repository, that will create your own copy of the Open Science Catalog. ( More information about how to do this in GitHub is available here: \n\nhttps://​docs​.github​.com​/en​/pull​-requests​/collaborating​-with​-pull​-requests​/working​-with​-forks​/fork​-a​-repo )\n\nOnce you have a OSC copy, you should have a look at the folder structure and information for an existing Item of the same type as the one you want to add - product, project, workflow, variable etc. This will give you an idea of the required information for a valid STAC Object. These STAC objects, stored as JSON files, are be automatically processed and rendered in the catalog viewer.\n\n","type":"content","url":"/osc-pr-manual#id-1-forking-the-repository","position":5},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)","lvl3":"2. Add the information about project/product/workflow/experiments/variables.","lvl2":"Adding information to the OSC"},"type":"lvl3","url":"/osc-pr-manual#id-2-add-the-information-about-project-product-workflow-experiments-variables","position":6},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)","lvl3":"2. Add the information about project/product/workflow/experiments/variables.","lvl2":"Adding information to the OSC"},"content":"After you forked the repository, you can start adding the required information. \n\nThis document explains the Open Science Catalog Extension to the SpatioTemporal Asset Catalog (STAC) specification. There are different requirements depending on the catalog entry you are trying to add.Sometimes its easier to copy the folder of existing project/product/workflow, rename it and start changing its information.\nFor example, copying the contents of this folder products/sentinel3-ampli-ice-sheet-elevation/, renaming it to products/New_Project_Name/ and editing its values.\n\n\n","type":"content","url":"/osc-pr-manual#id-2-add-the-information-about-project-product-workflow-experiments-variables","position":7},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)","lvl4":"2.1 Add new Project","lvl3":"2. Add the information about project/product/workflow/experiments/variables.","lvl2":"Adding information to the OSC"},"type":"lvl4","url":"/osc-pr-manual#id-2-1-add-new-project","position":8},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)","lvl4":"2.1 Add new Project","lvl3":"2. Add the information about project/product/workflow/experiments/variables.","lvl2":"Adding information to the OSC"},"content":"Projects are the containers that have the top level information about your work. It is the first type of information you should provide. Typically an OSC project corresponds to a project financed by the European Space Agency - Earth Observation programme. Before creating new project, check if your project is not already on the \n\nlist of onboarded projects. In such case you can use your project entry and only update it where needed.\n\nField\n\nDescription\n\nSTAC representation\n\nProject_ID\n\nNumeric identifier\n\n\n\nStatus\n\n“ongoing” or “completed”\n\nosc:status property\n\nProject_Name\n\nName\n\ntitle property\n\nShort_Description\n\n\n\ndescription property\n\nWebsite\n\n\n\nlink\n\nEo4Society_link\n\n\n\nlink\n\nConsortium\n\n\n\ncontacts[].name property\n\nStart_Date_Project\n\n\n\nextent.temporal[] property\n\nEnd_Date_Project\n\n\n\nextent.temporal[] property\n\nTO\n\n\n\ncontacts[].name property\n\nTO_E-mail\n\n\n\ncontacts[].emails[].value property\n\nTheme1 - Theme6\n\nTheme identifiers\n\nosc:themes property\n\nMetadata of each project is stored in a folder named after their unique id (collectionid). Each folder has one file - collection.json that has all the project information (metadata). Have a look at the structure of the Project entry below (with example values filled in):{\n    'type': 'Collection', // This is the STAC type specification. You dont need to change this\n    'stac_version': '1.1.0',  // This is the STAC version specification. You dont need to change this\n    'id': 'worldcereal2', // This is your project id. Please make sure to use unique id name for your project! The parent folder of the collection.json should have the same name as this id (not displayed in the browser).\n    'title': 'WorldCereal2', // Title of your project. Official acronym of the project may be used as well (this will be displayed to public)\n    'description': 'WorldCereal is an ESA initiative that provides global '\n                'cropland and crop type maps at 10-meter resolution, offering '\n                'seasonally updated data on temporary crops, croptypes (maize, '\n                'winter cereals and spring cereals), and irrigation.', // A short, but meaningful description of your project.\n    'links': [  // links to related elements of the catalog. The first two links should always be present and are always the same.\n        {'href': '../../catalog.json',\n        'rel': 'root',\n        'title': 'Open Science Catalog',\n        'type': 'application/json'},\n        {'href': '../catalog.json',\n        'rel': 'parent',\n        'title': 'Projects',\n        'type': 'application/json'},\n        // The next two links are external links to project websites.  These are mandatory and you have to adapt them to your project.\n        {'href': 'https://esa-worldcereal.org/en', # your dedicated project page\n            'rel': 'via',\n            'title': 'Website'},\n           {'href': 'https://eo4society.esa.int/projects/worldcereal-global-crop-monitoring-at-field-scale/', #link to the project page on EO4Society website\n            'rel': 'via',\n            'title': 'EO4Society Link'},\n        // The next link is a link to the themes specified in the themes field below. It is mandatory to have a link to all themes specified in the themes array\n        {'href': '../../themes/land/catalog.json',  #related theme of the project\n            'rel': 'related',\n            'title': 'Theme: Land',\n            'type': 'application/json'}\n    ],\n\n    'themes': [ // this is an array of the ESA themes the project relates to. The fields are restricted to the themes available in the OCS. The format of the array is id:theme and having at least one theme is mandatory. Check available themes here: https://opensciencedata.esa.int/themes/catalog\n        {'concepts': [{'id': 'land'}], \n        'scheme': 'https://github.com/stac-extensions/osc#theme'}\n    ],\n\n    'stac_extensions': [ // which schemas is the project information validated against. Typically you would not change these.\n        'https://stac-extensions.github.io/osc/v1.0.0/schema.json', \n        'https://stac-extensions.github.io/themes/v1.0.0/schema.json',\n        'https://stac-extensions.github.io/contacts/v0.1.1/schema.json'\n        ]\n    'osc:status': 'completed', // status of the project - Select from: completed, ongoing, scheduled\n    'osc:type': 'project', // Type of OSC STAC collection, for projects should always be project\n    'updated': '2025-07-14T17:03:29Z', // when was last update made\n    'extent': {'spatial': {'bbox': [[-180.0, -90.0, 180.0, 90.0]]}, // The study area of the project and its planned duration.\n                'temporal': {'interval': [['2021-01-01T00:00:00Z',\n                                        '2021-12-31T23:59:59Z']]}}\n    'license': 'proprietary' // Top level license of project outcomes. Should be one of https://github.com/ESA-EarthCODE/open-science-catalog-validation/blob/main/schemas/license.json\n\n    // list of consortium members working on the project and contact to ESA TO following the project. This field is required.\n    'contacts': [{'emails': [{'value': 'Zoltan.Szantoi@esa.int'}],\n               'name': 'Zoltan Szantoi',\n               'roles': ['technical_officer']},\n              {'name': 'VITO Remote Sensing', 'roles': ['consortium_member']}\n \n }\n\n\nIn addition to specifying the links within the project collection.json entry (created above), you should also add an entry in the parent catalog, listing all projects to be correclty rendered into STAC Browser. Once done it is required to add the following link (as provided below) to: projects/catalog.json . \nAdd this links array into the project/catalog.json just after the last project entry. Edit the catalog.json direclty by copy-and paste the followinf link (updated according to the data from your collection.json){\n    'rel':'child', \n    'target: './{project_id}/collection.json', // use the collectionid of the project\n    'media_type': 'application/json',\n    'title': '{project_title}'   // title of th project as described in the collection.json file created before. \n}\n\n","type":"content","url":"/osc-pr-manual#id-2-1-add-new-project","position":9},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)","lvl4":"2.2 Add new Product","lvl3":"2. Add the information about project/product/workflow/experiments/variables.","lvl2":"Adding information to the OSC"},"type":"lvl4","url":"/osc-pr-manual#id-2-2-add-new-product","position":10},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)","lvl4":"2.2 Add new Product","lvl3":"2. Add the information about project/product/workflow/experiments/variables.","lvl2":"Adding information to the OSC"},"content":"Products represent the outputs of you projects and typically reference datasets. Similarly to Projects, they are STAC items and follow similar structure, with some additional fields, improving their findability.\n\nField\n\nDescription\n\nSTAC representation\n\nID\n\nNumeric identifier\n\n\n\nStatus\n\n“ongoing” or “completed”\n\nosc:status property\n\nProject\n\nThe project identifier\n\nosc:project property, collection link\n\nWebsite\n\n\n\nlink\n\nProduct\n\nName\n\nlink\n\nShort_Name\n\n\n\nidentifier\n\nDescription\n\n\n\ndescription property\n\nAccess\n\nURL\n\nlink\n\nDocumentation\n\nURL\n\nlink\n\nVersion\n\n\n\nversion property\n\nDOI\n\nDigital Object Identifier\n\nsci:doi property and cite-as link\n\nVariable\n\nVariable identifier\n\ncollection link\n\nStart\n\n\n\nextent.temporal[]\n\nEnd\n\n\n\nextent.temporal[]\n\nRegion\n\n\n\nosc:region property\n\nPolygon\n\n\n\ngeometry\n\nReleased\n\n\n\ncreated property\n\nTheme1 - Theme6\n\nTheme identifiers\n\nosc:themes property\n\nEO_Missions\n\nSemi-colon separated list of missions\n\nosc:missions property\n\nStandard_Name\n\n\n\ncf:parameter.name property{\n 'type': 'Collection', // This is the STAC type specification. You dont need to change this\n 'id': 'worldcereal-crop-extent-belgium2', // This is the unique id of the product. Typically contains the dataset title+project name (or acronym)\n 'stac_version': '1.0.0', // This is the STAC version specification. You dont need to change this\n 'stac_extensions': [  // which schemas is the product information validated against. Typically you would not change these.\n    'https://stac-extensions.github.io/osc/v1.0.0/schema.json',\n    'https://stac-extensions.github.io/themes/v1.0.0/schema.json',\n    'https://stac-extensions.github.io/cf/v0.2.0/schema.json'\n ],\n 'created': '2025-07-14T17:37:16Z', //initial creation date\n 'updated': '2025-07-14T17:37:16Z'  // date of the last update\n 'title': 'WorldCereal Crop Extent - Belgium2', // product title\n 'description': 'WorldCereal is an ESA initiative that provides global ' // Short, but meaningful product description. It should provide enough information to the external users on the specific product.\n                'cropland and crop type maps at 10-meter resolution, offering '\n                'seasonally updated data on temporary crops, croptypes (maize, '\n                'winter cereals and spring cereals), and irrigation. This '\n                'dataset provides the outputs for Belgium.',\n\n 'extent': {'spatial': {'bbox': [[-180.0, -90.0, 180.0, 90.0]]}, // the temporal and spatial extent of the product\n            'temporal': {'interval': [['2021-01-01T00:00:00Z',\n                                       '2021-12-31T23:59:59Z']]}},\n 'keywords': ['Crops', 'Cereal'], // list of keywords associated with the product. These are expected to be inline with the description.\n\n 'osc:project': 'worldcereal2', //unique id of the OSC project, this product is associated with. It must be the id provided in the ./project/(collectionid)\n 'osc:region': 'Belgium', //text description of the study area\n 'osc:status': 'ongoing', //product status\n 'osc:type': 'product', // Type of OSC STAC collection, for products should always be product\n \n 'links': [ // links to different elements of the catalog. The first two links should always be present and are always the same.\n    \n    {'href': '../../catalog.json',\n    'rel': 'root',\n    'title': 'Open Science Catalog',\n    'type': 'application/json'},\n    {'href': '../catalog.json',\n    'rel': 'parent',\n    'title': 'Products',\n    'type': 'application/json'},\n    {'href': '../../projects/worldcereal2/collection.json', // link to parent project (associated project)\n    'rel': 'related',\n    'title': 'Project: WorldCereal2',\n    'type': 'application/json'},\n\n    {'href': '../../themes/land/catalog.json', // link to the theme (scientific domain) this product is associated with.\n    'rel': 'related',\n    'title': 'Theme: Land',\n    'type': 'application/json'},\n    {'href': '../../eo-missions/sentinel-2/catalog.json', // link to eo-missions used to produce the outcomes\n    'rel': 'related',\n    'title': 'EO Mission: Sentinel-2',\n    'type': 'application/json'},\n    {'href': '../../variables/crop-yield-forecast/catalog.json', // link to variables specified below.\n    'rel': 'related',\n    'title': 'Variable: Crop Yield Forecast',\n    'type': 'application/json'},\n\n    {'href': 'https://eoresults.esa.int/browser/#/external/eoresults.esa.int/stac/collections/ESA_WORLDCEREAL_SPRINGCEREALS', // link to dataset hosted in ESA Project Results Repository (PRR). \n    'rel': 'child',\n    'title': 'ESA WorldCereal Spring Cereals'},\n\n    {'href': 'https://eoresults.esa.int/browser/#/external/eoresults.esa.int/stac/collections/ESA_WORLDCEREAL_SPRINGCEREALS',\n    'rel': 'via',\n    'title': 'Access'}, // external link to the actual data\n    {'href': 'https://worldcereal.github.io/worldcereal-documentation/',\n    'rel': 'via',\n    'title': 'Documentation'} // external link to data documentation\n],\n 'osc:missions': ['sentinel-2'], // array of ESA missions related to the product. This array of values is mandatory and limited to missions already existing in the OSC. If you would like to associate your product to a mission that is not on the list, create eo-mission entry first. \n 'osc:variables': ['crop-yield-forecast'], // array of variables related to the product. This array of values is mandatory and limited to variables already existing in the OSC. If you would like to associate your product to a mission that is not on the list, create eo-mission entry first. \n 'cf:parameter': [{'name': 'crop-yield-forecast'}], // optional parameters following cf conventions\n \n 'sci:doi': 'https://doi.org/10.57780/s3d-83ad619', // DOI, if already assigned\n \n 'themes': [ // this is an array of the ESA themes the project relates to. The fields are restricted to the themes available in the OCS. The format of the array is id:theme and having at least one theme is mandatory.\n    {'concepts': [{'id': 'land'}],\n    'scheme': 'https://github.com/stac-extensions/osc#theme'}],\n \n 'license': 'proprietary', //  License of the product. Should be one of https://github.com/ESA-EarthCODE/open-science-catalog-validation/blob/main/schemas/license.json\n\n}\n\n\nIn addition to specifying the links from the product to other parts of the catalog, it is required to add the reverse links, as in case of the Project to following elements:\n\nFrom the Product Collection.json to the Catalog.json (listing all products in the OSC)\n\nFrom the associated Project to the Product\n\nFrom the associated EO-Missions catalog to the Product\n\nFrom the associated Variables Catalog to the Product\n\nFrom the associated Themes Catalog to the Product\n\nAdd the Product link to products/catalog.json by pasting the following in the links array:{\n    'rel':'child', \n    'target: './worldcereal-crop-extent-belgium2/collection.json', // use the collectionid of the product\n    'media_type': 'application/json',\n    'title': 'WorldCereal Crop Extent - Belgium2'   // title of the product as described in the collection.json file created before. \n}\n\nAdd the links array to associated elements of the OSC. For example add following product to parent project:{\n      \"rel\": \"related\",\n      \"href\": \"../../products/worldcereal-crop-extent-belgium2/collection.json\",\n      \"type\": \"application/json\",\n      \"title\": \"Product: WorldCereal Crop Extent - Belgium2\"\n}\n\nSimilarly, add links to other OSC elements like eo-missions, variables, themes etc.\n\n","type":"content","url":"/osc-pr-manual#id-2-2-add-new-product","position":11},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)","lvl4":"2.3 Add new Workflow","lvl3":"2. Add the information about project/product/workflow/experiments/variables.","lvl2":"Adding information to the OSC"},"type":"lvl4","url":"/osc-pr-manual#id-2-3-add-new-workflow","position":12},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)","lvl4":"2.3 Add new Workflow","lvl3":"2. Add the information about project/product/workflow/experiments/variables.","lvl2":"Adding information to the OSC"},"content":"Workflows are the code and workflows associated with a project, that have been used to generate a specific product. Workflows follow OGC record specifications in contrast to OSC Projects and Products entries. However, the metadata of a workflow is also expressed in JSON format.\n\nField Name\n\nDescription\n\nconformsTo\n\nAn array of URIs indicating which OGC API Records specifications this record conforms to.\n\ntype\n\nIndicates the GeoJSON object type. Required to be \"Feature\" for OGC compliance.\n\ngeometry\n\nSpatial representation of the item. Set to None here, as it may not be spatially explicit.\n\nlinkTemplates\n\nAn array of link templates as per the OGC API. Used for dynamic link generation.\n\nid\n\nUnique identifier for the workflow STAC item ('worldcereal-workflow2').\n\nlinks\n\nList of external and internal references including catalog navigation, project association, theme association, process graph, source code, and service endpoint.\n\nproperties.contacts\n\nList of individuals or organizations associated with the workflow. Each contact may include name, email, and roles such as technical_officer or consortium_member.\n\nproperties.created\n\nTimestamp representing when the workflow was first created (2025-07-14T18:02:13Z).\n\nproperties.updated\n\nTimestamp of the most recent update to the workflow (2025-07-14T18:02:13Z).\n\nproperties.version\n\nThe version number of the workflow (1).\n\nproperties.title\n\nA concise, descriptive title of the workflow: “ESA worldcereal global crop extent detector2”.\n\nproperties.description\n\nA summary of what the workflow does: “Detects crop land at 10m resolution, trained for global use...”.\n\nproperties.keywords\n\nArray of keywords to support discoverability (e.g., agriculture, crops).\n\nproperties.themes\n\nArray of themes the workflow relates to. Each entry includes a concepts array with IDs (e.g., 'land') and a scheme URL.\n\nproperties.formats\n\nOutput formats of the workflow (e.g., GeoTIFF).\n\nproperties.osc:project\n\nProject ID associated with the workflow (worldcereal2).\n\nproperties.osc:status\n\nCurrent status of the workflow (e.g., completed).\n\nproperties.osc:type\n\nType of OSC object, expected to be workflow.\n\nproperties.license\n\nLicense for the workflow (e.g., 'varuious' – likely a typo for various).\n\nAll data is stored in a record.json file, witin a folder that has the same name as the workflow id.{\n    'conformsTo': [ // OGC spec, does not need to change\n        'http://www.opengis.net/spec/ogcapi-records-1/1.0/req/record-core' \n    ],\n    'type': 'Feature'// OGC spec requirement, does not need to change\n    'geometry': None, // OGC spec requirement, does not need to change\n    'linkTemplates': [], // OGC spec, does not need to change\n    'id': 'worldcereal-workflow2',  // unique workflow id\n\n    'links': [  // links to different parts of the catalog. The first two links should always be present and are always the same.\n        \n        {'href': '../../catalog.json',\n            'rel': 'root',\n            'title': 'Open Science Catalog',\n            'type': 'application/json'},\n        {'href': '../catalog.json',\n            'rel': 'parent',\n            'title': 'Workflows',\n            'type': 'application/json'},\n        {'href': '../../projects/worldcereal2/collection.json', // link to associated project\n            'rel': 'related',\n            'title': 'Project: WorldCereal2',\n            'type': 'application/json'},\n        {'href': '../../themes/land/catalog.json', // link to associated themes in the themes array specified below\n        'rel': 'related',\n        'title': 'Theme: Land',\n        'type': 'application/json'},\n        { // link to the openeo-process process graph that describes the workflow\n            'href': 'https://raw.githubusercontent.com/WorldCereal/worldcereal-classification/refs/tags/worldcereal_crop_extent_v1.0.1/src/worldcereal/udp/worldcereal_crop_extent.json',\n            'rel': 'openeo-process',\n            'title': 'openEO Process Definition',\n            'type': 'application/json'},\n        { // external link to the full workflow codebase\n            'href': 'https://github.com/WorldCereal/worldcereal-classification.git',\n            'rel': 'git',\n            'title': 'Git source repository',\n            'type': 'application/json'},\n        { // external link to the service used to run the workflow\n            'href': 'https://openeofed.dataspace.copernicus.eu',\n            'rel': 'service',\n            'title': 'CDSE openEO federation',\n            'type': 'application/json'}\n        ],\n    // OGC spec requirement to have a properties field, that contains most of the workflow metadata\n\n    'properties': {\n        \n        'contacts': [{'emails': [{'value': 'marie-helene.rio@esa.int'}],\n                                'name': 'Marie-Helene Rio',\n                                'roles': ['technical_officer']},\n                                {'name': 'CNR-INSTITUTE OF MARINE SCIENCES-ISMAR '\n                                        '(IT)',\n                                'roles': ['consortium_member']},\n                                {'name': '+ATLANTIC – Association for an Atla '\n                                        '(PT)',\n                                'roles': ['consortium_member']}],\n        'created': '2025-07-14T18:02:13Z', // date of workflow creation\n        'updated': '2025-07-14T18:02:13Z', // date of workflow last update\n        'version': '1' //  workflow version\n        'title': 'ESA worldcereal global crop extent detector2', // Short and meaningful title of the workflow\n        'description': 'Detects crop land at 10m resolution, trained '\n                    'for global use. Based on Sentinel-1 and 2 '\n                    'data...', // Short and meaningful workflow description. Should provide specification on how the workflow can be executed and what it does.\n        'keywords': ['agriculture', 'crops'], // workflow keywords (to enhance the findability of the workflow)\n        'themes': [{'concepts': [{'id': 'land'}], // // this is an array of the ESA themes the project relates to. The fields are restricted to the themes available in the OCS. The format of the array is id:theme and having atleast one theme is mandatory.\n                            'scheme': 'https://github.com/stac-extensions/osc#theme'\n                    }],\n        'formats': [{'name': 'GeoTIFF'}], //format of worfklow output\n        'osc:project': 'worldcereal2', // workflow related project\n        'osc:status': 'completed', // workflow status\n        'osc:type': 'workflow', // OSC type, for workflows should always be workflow\n        'license': 'varuious', // workflow license\n        \n    }\n}\n\nIn addition to specifying the links from the workflow to other parts of the catalog, it is required to add the reverse links:\n\nFrom the Workflow record.json to the workflows/catalog.json (listing all workflows in the OSC)\n\nFrom the associated Project to the Workflow\n\nFrom the associated Themes to the Workflow\n\n","type":"content","url":"/osc-pr-manual#id-2-3-add-new-workflow","position":13},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)","lvl3":"3. Open a PR to merge the new information into the OSC.","lvl2":"Adding information to the OSC"},"type":"lvl3","url":"/osc-pr-manual#id-3-open-a-pr-to-merge-the-new-information-into-the-osc","position":14},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)","lvl3":"3. Open a PR to merge the new information into the OSC.","lvl2":"Adding information to the OSC"},"content":"After you have added all the information, commit and push your changes to the forked repository and open a pull request against the OSC - \n\nhttps://​docs​.github​.com​/en​/pull​-requests​/collaborating​-with​-pull​-requests​/proposing​-changes​-to​-your​-work​-with​-pull​-requests​/creating​-a​-pull​-request .\n\nOnce you open the PR, there will be an automatic validation run against the information you added . If it fails you will have to change some of the added information. You can see if the PR is successfull based on the specific CI run, in the screen shot below. If you click on the red X, the validator will give you the specific reason for the failure. \nPlease be advised that once a pull request (PR) is submitted to the open-science-catalog-metadata repository, it will undergo a review process conducted by members of the EarthCODE team. During this process, the content will be evaluated for completeness and accuracy. Should any additional information or modifications be required, you may be asked to update your PR accordingly. All communication related to the review will be provided through comments within the PR.\n\n","type":"content","url":"/osc-pr-manual#id-3-open-a-pr-to-merge-the-new-information-into-the-osc","position":15},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)","lvl2":"Alternatives"},"type":"lvl2","url":"/osc-pr-manual#alternatives","position":16},{"hierarchy":{"lvl1":"Adding new content to Open Science Catalogue with Pull Request (PR)","lvl2":"Alternatives"},"content":"EarthCODE provides a \n\nGUI editor to automatically create links and open a PR for you.\n\nIf you are using one of the EarthCODE platforms, they provide specialised tools for automatic this work.\n\nYou can use libraries like pystac to automate some of the required work. This tutorial shows how.","type":"content","url":"/osc-pr-manual#alternatives","position":17},{"hierarchy":{"lvl1":"Generating OSC information using pystac"},"type":"lvl1","url":"/osc-pr-pystac","position":0},{"hierarchy":{"lvl1":"Generating OSC information using pystac"},"content":"This notebook shows how to generate OSC Projects, Products and Workflows using pystac. EarthCODE provides a \n\nGUI editor that offers this and more functionality, including a user interface. However, if you decide to manually create items, using a library like pystac can save some time.\nThe code described here does not carry out all the required steps to pass the automated OSC validation. For example, you still have to generate all return links as described in the manual PR tutorial. You’ll also have to manually open the PR in the end.\n\nNOTE: Before you run the notebook you’ll need a fork of the open-science-catalog-metadata repository. See the Manual PR Tutorial about how to do it.","type":"content","url":"/osc-pr-pystac","position":1},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl3":"Import libraries"},"type":"lvl3","url":"/osc-pr-pystac#import-libraries","position":2},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl3":"Import libraries"},"content":"\n\nimport pystac\nfrom datetime import datetime\nfrom pystac.extensions.projection import ProjectionExtension\n\n","type":"content","url":"/osc-pr-pystac#import-libraries","position":3},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl3":"Get all entries from the Open Science Catalog"},"type":"lvl3","url":"/osc-pr-pystac#get-all-entries-from-the-open-science-catalog","position":4},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl3":"Get all entries from the Open Science Catalog"},"content":"\n\n# read the catalog root\ncatalog = pystac.Catalog.from_file('../../open-science-catalog-metadata/catalog.json')\n\n# access the list of the themes in open science catalog\nthemes = catalog.get_child('themes')\nallowed_themes = [child.id for child in themes.get_children()]\n\n\n# access the list of available ESA missions\nmissions = catalog.get_child('eo-missions')\nallowed_missions = [child.id for child in missions.get_children()]\n\n# access the list of avaiable variables\nvariables = catalog.get_child('variables')\nallowed_variables = [child.id for child in variables.get_children()]\n\n# access the list of existing projects, products and workflows\nproducts = catalog.get_child('products')\nprojects = catalog.get_child('projects')\nworkflows = catalog.get_child('workflows')\n\n","type":"content","url":"/osc-pr-pystac#get-all-entries-from-the-open-science-catalog","position":5},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl3":"Define helper functions | Add new variables, theme and eo missions"},"type":"lvl3","url":"/osc-pr-pystac#define-helper-functions-add-new-variables-theme-and-eo-missions","position":6},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl3":"Define helper functions | Add new variables, theme and eo missions"},"content":"\n\ndef add_product_variables(collection, variables_to_add):\n    '''Add variables to the collection custom fields and add links to the missions collection.'''\n    \n    for variable in variables_to_add:\n        \n        assert variable in allowed_variables\n\n        # add the correct link\n        collection.add_link(\n            pystac.Link(rel=\"related\", \n                        target=variables.get_child(variable).get_links('self')[0].href, \n                        media_type=\"application/json\",\n                        title=f\"Variable: {variables.get_child(variable).title}\")\n        )\n\n    # Add themes to the custom fields\n    collection.extra_fields.update({\n        \"osc:variables\": variables_to_add\n    })\n\ndef add_themes(collection, themes_to_add):\n    '''Add themes to the collection custom fields and add links to the themes collection.'''\n    \n    themes_list = []\n    for theme in themes_to_add:\n        \n        assert theme in allowed_themes\n\n        # add the correct link\n        collection.add_link(\n            pystac.Link(rel=\"related\", \n                        target=themes.get_child(theme).get_links('self')[0].href, \n                        media_type=\"application/json\",\n                        title=f\"Theme: {themes.get_child(theme).title}\")\n        )\n        \n        themes_list.append(\n            {\n                \"scheme\": \"https://github.com/stac-extensions/osc#theme\",\n                \"concepts\": [{\"id\": theme}]\n            }\n        )\n\n    # Add themes to the custom fields\n    collection.extra_fields.update({\n        \"themes\": themes_list\n    }\n    )\n\n\ndef add_links(collection, relations, targets, titles):\n\n    '''Add links from the collection to outside websites.'''\n    links = []\n    \n    for rel, target, title in zip(relations, targets, titles):\n        links.append(pystac.Link(rel=rel, target=target, title=title)),\n    \n    collection.add_links(links)\n\n\ndef create_contract(name, roles, emails):\n    '''Create a contact template'''\n    contact =  {\n        \"name\": name,\n        \"roles\": [r for r in roles]\n    }\n    if emails:\n        contact['emails'] = [{\"value\":email} for email in emails]\n    return contact\n\ndef add_product_missions(collection, missions_to_add):\n    '''Add missions to the collection custom fields and add links to the missions collection.'''\n    \n    for mission in missions_to_add:\n        \n        assert mission in allowed_missions\n\n        # add the correct link\n        collection.add_link(\n            pystac.Link(rel=\"related\", \n                        target=missions.get_child(mission).get_links('self')[0].href, \n                        media_type=\"application/json\",\n                        title=f\"EO Mission: {missions.get_child(mission).title}\"\n            )\n        )\n\n    # Add themes to the custom fields\n    collection.extra_fields.update({\n         \"osc:missions\": missions_to_add\n    }\n    )\n\n\n","type":"content","url":"/osc-pr-pystac#define-helper-functions-add-new-variables-theme-and-eo-missions","position":7},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl3":"Define helper functions | Create new project collection"},"type":"lvl3","url":"/osc-pr-pystac#define-helper-functions-create-new-project-collection","position":8},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl3":"Define helper functions | Create new project collection"},"content":"\n\n\ndef create_project_collection(project_id, project_title, project_description, \n                      project_status, extent, project_license):\n\n    '''Create project collection template from the provided information.'''\n\n    # Create the collection\n    collection = pystac.Collection(\n        id=project_id,\n        description=project_description,\n        extent=extent,\n        license=project_license,\n        title=project_title,\n        extra_fields = {\n            \"osc:status\": project_status,\n            \"osc:type\": \"project\",\n            \"updated\": datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n        },\n        stac_extensions=[\n            \"https://stac-extensions.github.io/osc/v1.0.0/schema.json\",\n            \"https://stac-extensions.github.io/themes/v1.0.0/schema.json\",\n            \"https://stac-extensions.github.io/contacts/v0.1.1/schema.json\"\n        ]\n    \n    )\n\n    # Add pre-determined links \n    collection.add_links([\n        pystac.Link(rel=\"root\", target=\"../../catalog.json\", media_type=\"application/json\", title=\"Open Science Catalog\"),\n        pystac.Link(rel=\"parent\", target=\"../catalog.json\", media_type=\"application/json\", title=\"Projects\"),\n        # pystac.Link(rel=\"self\", target=f\"https://esa-earthcode.github.io/open-science-catalog-metadata/projects/{project_id}/collection.json\", media_type=\"application/json\"),\n    ])\n\n    return collection\n\n\n\n","type":"content","url":"/osc-pr-pystac#define-helper-functions-create-new-project-collection","position":9},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl3":"Define helper functions | Create new product collection"},"type":"lvl3","url":"/osc-pr-pystac#define-helper-functions-create-new-product-collection","position":10},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl3":"Define helper functions | Create new product collection"},"content":"\n\ndef create_product_collection(product_id, product_title, product_description, product_extent, product_license,\n                              product_keywords, product_status, product_region, product_project_id, product_project_title,\n                              product_parameters=None, product_doi=None):\n\n    collection = pystac.Collection(\n            id=product_id,\n            title=product_title,\n            description=product_description,\n            extent=product_extent,\n            license=product_license,\n            keywords=product_keywords,\n            stac_extensions=[\n                \"https://stac-extensions.github.io/osc/v1.0.0/schema.json\",\n                \"https://stac-extensions.github.io/themes/v1.0.0/schema.json\",\n                \"https://stac-extensions.github.io/cf/v0.2.0/schema.json\"\n            ],\n        )\n    \n    # Add pre-determined links \n    collection.add_links([\n        pystac.Link(rel=\"root\", target=\"../../catalog.json\", media_type=\"application/json\", title=\"Open Science Catalog\"),\n        pystac.Link(rel=\"parent\", target=\"../catalog.json\", media_type=\"application/json\", title=\"Products\"),\n        # pystac.Link(rel=\"self\", target=f\"https://esa-earthcode.github.io/open-science-catalog-metadata/products/{project_id}/collection.json\", media_type=\"application/json\"),\n        pystac.Link(rel=\"related\", target=f\"../../projects/{product_project_id}/collection.json\", media_type=\"application/json\", title=f\"Project: {product_project_title}\"),\n\n    ])\n\n    # Add extra properties\n    collection.extra_fields.update({\n        \"osc:project\": product_project_id,\n        \"osc:status\": product_status,\n        \"osc:region\": product_region,\n        \"osc:type\": \"product\",\n        \"created\": datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n        \"updated\": datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n    })\n\n    if product_doi is not None:\n        collection.extra_fields[\"sci:doi\"] = product_doi\n\n\n    if product_parameters:\n        collection.extra_fields[\"cf:parameter\"] = [{\"name\": p} for p in product_parameters]\n    \n    return collection\n\n","type":"content","url":"/osc-pr-pystac#define-helper-functions-create-new-product-collection","position":11},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl3":"Define helper functions | Create new workflow record"},"type":"lvl3","url":"/osc-pr-pystac#define-helper-functions-create-new-workflow-record","position":12},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl3":"Define helper functions | Create new workflow record"},"content":"\n\ndef create_workflow_collection(workflow_id, workflow_title, \n                               workflow_description, workflow_license, workflow_extent,\n                               workflow_keywords, workflow_formats, workflow_project, workflow_project_title):\n\n    '''Create a workflow collection template from the provided information.'''\n\n    # Create the collection\n\n    collection = {\n        'id': workflow_id,\n        'type': 'Feature',\n        'geometry': None,\n        \"conformsTo\": [\"http://www.opengis.net/spec/ogcapi-records-1/1.0/req/record-core\"],\n        \"properties\": {\n            \"title\": workflow_title,\n            \"description\": workflow_description,\n            \"osc:type\": \"workflow\",\n            \"osc:project\": workflow_project,\n            \"osc:status\": \"completed\",\n            \"formats\": [{\"name\": f} for f in workflow_formats],\n            \"updated\": datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n            \"created\": datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n            \"keywords\": workflow_keywords,\n            \"license\": workflow_license,\n            \"version\": \"1\"\n        },\n        \"linkTemplates\": [],\n        \"links\": [\n            \n            {\n                \"rel\": \"root\",\n                \"href\": \"../../catalog.json\",\n                \"type\": \"application/json\",\n                \"title\": \"Open Science Catalog\"\n            },            \n            {\n                \"rel\": \"parent\",\n                \"href\": \"../catalog.json\",\n                \"type\": \"application/json\",\n                \"title\": \"Workflows\"\n            },            \n  \n            {\n                \"rel\": \"related\",\n                \"href\": f\"../../projects/{workflow_project}/collection.json\",\n                \"type\": \"application/json\",\n                \"title\": f\"Project: {workflow_project_title}\"\n            },\n            \n        ]\n\n    }\n    \n    return collection\n\n\n","type":"content","url":"/osc-pr-pystac#define-helper-functions-create-new-workflow-record","position":13},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl2":"Create a metadata collection for new project"},"type":"lvl2","url":"/osc-pr-pystac#create-a-metadata-collection-for-new-project","position":14},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl2":"Create a metadata collection for new project"},"content":"\n\n# Define id, title, description, project status, license\nproject_id = \"worldcereal2\"\nproject_title = \"WorldCereal2\"\nproject_description = \"WorldCereal is an ESA initiative that provides global cropland and crop type maps at 10-meter resolution, offering seasonally updated data on temporary crops, croptypes (maize, winter cereals and spring cereals), and irrigation.\"\nproject_status = \"completed\"\nproject_license = 'proprietary'\n\n# Define spatial and temporal extent\nspatial_extent = pystac.SpatialExtent([[-180.0, -90.0, 180.0, 90.0]])\ntemporal_extent = pystac.TemporalExtent([[datetime(2021, 1, 1), datetime(2021, 12, 31, 23, 59, 59)]])\nextent = pystac.Extent(spatial=spatial_extent, temporal=temporal_extent)\n\n# Define links and link titles\nproject_link_targets = [\"https://esa-worldcereal.org/en\", \n                        \"https://eo4society.esa.int/projects/worldcereal-global-crop-monitoring-at-field-scale/\"]\nproject_link_relations = [\"via\", \"via\"]\nproject_link_titles = [\"Website\", \"EO4Society Link\"]\n\n# Define project themes\nproject_themes = [\"land\"]\n\n# contacts\nproject_contracts_info = [\n    (\"Zoltan Szantoi\", [\"technical_officer\"], [\"Zoltan.Szantoi@esa.int\"]),\n    (\"VITO Remote Sensing\", [\"consortium_member\"], None)\n]\n\ncollection = create_project_collection(project_id, project_title, project_description, \n                      project_status, extent, project_license)\n\n# add links\nadd_links(collection, project_link_relations, project_link_targets, project_link_titles)\n\n## add themes\nadd_themes(collection, project_themes)\n\n\n# Add contacts\ncollection.extra_fields.update({\n\n    \"contacts\": [create_contract(*info) for info in project_contracts_info]\n    \n})\n\ncollection.validate()\n\ncollection\n\n# save this file and copy it to the catalog/projects/{project}/collection.json\ncollection.save_object(dest_href='project_collection.json')\n\n# optionally run this code to transfer the generated file to the OSC folder, ready to be commited.\n!mkdir -p ../open-science-catalog-metadata-staging/projects/worldcereal2/\n!cp project_collection.json ../open-science-catalog-metadata-staging/projects/worldcereal2/collection.json\n\n","type":"content","url":"/osc-pr-pystac#create-a-metadata-collection-for-new-project","position":15},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl2":"Create a metadata collection for new product"},"type":"lvl2","url":"/osc-pr-pystac#create-a-metadata-collection-for-new-product","position":16},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl2":"Create a metadata collection for new product"},"content":"\n\nproduct_id = \"worldcereal-crop-extent-belgium2\"\nproduct_title = \"WorldCereal Crop Extent - Belgium2\"\nproduct_description = \"WorldCereal is an ESA initiative that provides global cropland and crop type maps at 10-meter resolution, offering seasonally updated data on temporary crops, croptypes (maize, winter cereals and spring cereals), and irrigation. This dataset provides the outputs for Belgium.\"\nproduct_keywords = [\n    \"Crops\",\n    \"Cereal\"\n]\nproduct_status = \"ongoing\"\nproduct_license = \"proprietary\"\n\n# Define spatial and temporal extent\nproduct_spatial_extent = pystac.SpatialExtent([[2.5135, 49.529, 6.156, 51.475]])\nproduct_temporal_extent = pystac.TemporalExtent([[datetime(2021, 1, 1), datetime(2021, 12, 31, 23, 59, 59)]])\nproduct_extent = pystac.Extent(spatial=product_spatial_extent, temporal=product_temporal_extent)\nproduct_region = \"Belgium\"\nproduct_themes = [\"land\"]\nproduct_missions = [ \"sentinel-2\"]\nproduct_variables = [  \"crop-yield-forecast\" ]\nproduct_parameters = [  \"crop-yield-forecast\" ]\n\nproduct_project_id = \"worldcereal2\"\nproduct_project_title = \"WorldCereal2\"\n\nproduct_doi = \"https://doi.org/10.57780/s3d-83ad619\"\n\n\n# define links to add\n\nproduct_target_relations = ['child', 'via', 'via']\nproduct_target_links = ['https://eoresults.esa.int/stac/collections/sentinel3-ampli-ice-sheet-elevation',\n                        'https://eoresults.esa.int/browser/#/external/eoresults.esa.int/stac/collections/sentinel3-ampli-ice-sheet-elevation',\n                        'https://eoresults.esa.int/d/sentinel3-ampli-ice-sheet-elevation/2025/05/07/sentinel-3-ampli-user-handbook/S3_AMPLI_User_Handbook.pdf']\nproduct_target_titles = ['PRR link', 'Access', 'Documentation']\n\n\nproduct_collection = create_product_collection(\n    product_id, product_title, product_description, product_extent, \n    product_license, product_keywords, product_status, product_region, \n    product_project_id, product_project_title, product_parameters, product_doi)\n\n# add themes\nadd_themes(product_collection, product_themes)\n\n\n\nadd_product_missions(product_collection, product_missions)\n\nadd_product_variables(product_collection, product_variables)\n\n# add links\nadd_links(product_collection,\n          product_target_relations,\n          product_target_links,\n          product_target_titles\n)\n\nproduct_collection.validate()\n\nproduct_collection\n\n# save this file and copy it to the catalog/products/{product_id}/collection.json\nproduct_collection.save_object(dest_href='product_collection.json')\n\n# optionally run this code to transfer the generated file to the OSC folder, ready to be commited.\n!mkdir -p ../open-science-catalog-metadata-staging/products/worldcereal-crop-extent-belgium2/\n!cp product_collection.json ../open-science-catalog-metadata-staging/products/worldcereal-crop-extent-belgium2/collection.json\n\n","type":"content","url":"/osc-pr-pystac#create-a-metadata-collection-for-new-product","position":17},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl2":"Create a metadata collection for new workflow"},"type":"lvl2","url":"/osc-pr-pystac#create-a-metadata-collection-for-new-workflow","position":18},{"hierarchy":{"lvl1":"Generating OSC information using pystac","lvl2":"Create a metadata collection for new workflow"},"content":"\n\nworkflow_id = \"worldcereal-workflow2\"\nworkflow_title=\"ESA worldcereal global crop extent detector2\"\nworkflow_description=\"Detects crop land at 10m resolution, trained for global use. Based on Sentinel-1 and 2 data...\"\nworkflow_license = \"proprietary\"\nworkflow_keywords= [\"agriculture\", \"crops\"]\nworkflow_formats = [\"GeoTIFF\"]\nworkflow_project = \"worldcereal2\"\nworkflow_project_title = \"WorldCereal2\"\n\nworkflow_themes = ['land']\n\n# Define spatial and temporal extent\nspatial_extent = pystac.SpatialExtent([[-180.0, -90.0, 180.0, 90.0]])\ntemporal_extent = pystac.TemporalExtent([[datetime(2022, 2, 1), datetime(2026, 1, 31, 23, 59, 59)]])\nworkflow_extent = pystac.Extent(spatial=spatial_extent, temporal=temporal_extent)\n\n\n# add custom theme schemas\n\nworkflow_contracts_info = [\n    (\"Marie-Helene Rio\", [\"technical_officer\"], [\"marie-helene.rio@esa.int\"]),\n    (\"CNR-INSTITUTE OF MARINE SCIENCES-ISMAR (IT)\", [\"consortium_member\"], None),\n    (\"+ATLANTIC – Association for an Atla (PT)\", [\"consortium_member\"], None),\n]\n\nworkflow_collection = create_workflow_collection(workflow_id, workflow_title, \n                               workflow_description, workflow_license, workflow_extent,\n                               workflow_keywords, workflow_formats, workflow_project, workflow_project_title)\n\n# add contacts\nworkflow_collection['properties'].update({\n\n    \"contacts\": [create_contract(*info) for info in workflow_contracts_info]\n    \n})\n\n\nworkflow_collection['properties']['themes'] = [\n    {\n        \"scheme\": \"https://github.com/stac-extensions/osc#theme\",\n        \"concepts\": [{\"id\": t} for t in workflow_themes]\n    }\n]\n\nfor t in workflow_themes:\n    workflow_collection['links'].append(\n            {\n                    \"rel\": 'related',\n                    \"href\": f\"../../{t}/land/catalog.json\",\n                    \"type\": \"application/json\",\n                    \"title\": f'Theme: {t.capitalize()}'\n                }\n)\n\nworkflow_target_relations = ['openeo-process', 'git', 'service']\nworkflow_target_links = ['https://raw.githubusercontent.com/WorldCereal/worldcereal-classification/refs/tags/worldcereal_crop_extent_v1.0.1/src/worldcereal/udp/worldcereal_crop_extent.json',\n                        'https://github.com/WorldCereal/worldcereal-classification.git',\n                        'https://openeofed.dataspace.copernicus.eu']\nworkflow_target_titles = ['openEO Process Definition', 'Git source repository', 'CDSE openEO federation']\n\nfor rel, link, title in zip(workflow_target_relations, workflow_target_links, workflow_target_titles):\n    workflow_collection['links'].append(\n        {\n                \"rel\": rel,\n                \"href\": link,\n                \"type\": \"application/json\",\n                \"title\": title\n            }\n    )\n\nimport json\nwith open('record.json', 'w') as f:\n    json.dump(workflow_collection, f)\n\n# optionally run this code to transfer the generated file to the OSC folder, ready to be commited.\n!mkdir -p ../open-science-catalog-metadata-staging/workflows/worldcereal-workflow2/\n!cp record.json ../open-science-catalog-metadata-staging/workflows/worldcereal-workflow2/record.json","type":"content","url":"/osc-pr-pystac#create-a-metadata-collection-for-new-workflow","position":19},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset"},"type":"lvl1","url":"/creating-stac-catalog-from-prr-example","position":0},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset"},"content":"This is an example notebook for creating the STAC Items uploaded to ESA Project Results Repository and made available at: \n\nhttps://​eoresults​.esa​.int​/browser​/​#​/external​/eoresults​.esa​.int​/stac​/collections​/sentinel3​-ampli​-ice​-sheet​-elevation\n\nDataset is also discoverable via Open Science Catalogue, providing access to created in this tutorial collection stored in ESA Project Results Repository (PRR).\n\n\nhttps://​opensciencedata​.esa​.int​/products​/sentinel3​-ampli​-ice​-sheet​-elevation​/collection\n\nIt focuses on generating metadata for a project with a hundreads of items, each of which has hundreads of netcdf assets.\n\nCheck the \n\nEarthCODE documentation, and \n\nPRR STAC introduction example for a more general introduction to STAC and the ESA PRR.\n\nThe code below demonstrates how to perform the necessary steps using real data from the ESA project **SRAL Processing over Land Ice\n**. With the focus of the project on improving Sentinel-3 altimetry performances over land ice.\n\n🔗 Check the : \n\nUser handbook\n\n🔗 Check the : \n\nScientifc publication","type":"content","url":"/creating-stac-catalog-from-prr-example","position":1},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl4":"Acknowledgment"},"type":"lvl4","url":"/creating-stac-catalog-from-prr-example#acknowledgment","position":2},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl4":"Acknowledgment"},"content":"We gratefully acknowledge the SRAL Processing over Land Ice team for providing access to the data used in this example, as well as support in creating it.","type":"content","url":"/creating-stac-catalog-from-prr-example#acknowledgment","position":3},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl3":"Steps described in this notebook"},"type":"lvl3","url":"/creating-stac-catalog-from-prr-example#steps-described-in-this-notebook","position":4},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl3":"Steps described in this notebook"},"content":"This notebook presents the workflow for generating a PRR Collection for the entire dataset coming from the project. To create a valid STAC Items and Collection you should follow steps described below:\n\nGenerate a root STAC Collection\n\nGroup your dataset files into STAC Items and STAC Assets\n\nAdd the Items to the collection\n\nSave the normalised collection\n\nDue to the complexity of the project and the time it takes to process the data, the STAC Items are generated first and stored locally. They are added to the collection afterwards.\nFurthermore, since we are working with thousands of files, we are using the links from the PRR directly. When the notebook was created originally all the files were available locally.\n\nThis notebook can be used as an example for following scenario(s):\n\nCreating the STAC Items from the files stored locally\n\nCreating the STAC Items from files stored in the s3bucket or other cloud repository\n\nCreating the STAC Items from files already ingested into PRR\n\nOf course if your files are locally stored, or stored in a different S3 Bucket the access to them (roor_url and items paths) should be adapted according to your dataset location.\n\nNote: Due to the original size of the dataset ~ 100GB, running this notebook end to end may take hours. We do advise therefore to trying it on your own datasets by changing file paths to be able to produe valid STAC Collaction and STAC Items.\n\n","type":"content","url":"/creating-stac-catalog-from-prr-example#steps-described-in-this-notebook","position":5},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl2":"Loading Libraries"},"type":"lvl2","url":"/creating-stac-catalog-from-prr-example#loading-libraries","position":6},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl2":"Loading Libraries"},"content":"\n\nimport json\nimport time\nimport pystac\nimport rasterio\nfrom shapely import box\nimport pandas as pd\nimport xarray as xr\nfrom datetime import datetime\nfrom dateutil.parser import isoparse\nfrom dateutil import parser\nfrom dateutil.parser import parse\n\n","type":"content","url":"/creating-stac-catalog-from-prr-example#loading-libraries","position":7},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl2":"2. Load Product files stored in ESA Project Results Repository"},"type":"lvl2","url":"/creating-stac-catalog-from-prr-example#id-2-load-product-files-stored-in-esa-project-results-repository","position":8},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl2":"2. Load Product files stored in ESA Project Results Repository"},"content":"\n\nroot_url = 'https://eoresults.esa.int' # provide a root url for the datasets items \n\n# get all items for the S3 AMPLI collection from the PRR STAC API\nitems = pystac.ItemCollection.from_file('https://eoresults.esa.int/stac/collections/sentinel3-ampli-ice-sheet-elevation/items?limit=10_000')\n\n# get the paths to all the data\n\n# using a dictionary is faster than using pystac\nitems_dict = items.to_dict()\nall_item_paths = []\nfor item in items_dict['features']:\n    assets = item['assets']\n    for asset_name, asset_dict in assets.items():\n        if asset_dict['roles'] == ['data']:\n            all_item_paths.append(asset_dict['href'])\n\n# Create a list of EO Missions and instruments as well as region of the dataset and cycles\ninstruments = ['sentinel-3a', 'sentinel-3b']\nregions = ['antarctica', 'greenland']\ncycles = [f\"cycle{str(i).zfill(3)}\" for i in range(5, 112)]  # Cycle005 to Cycle111\n\n# Assign the instrument name based on the acronym used in the file name\nrenaming = {\n    'S3A': 'sentinel-3a',\n    'S3B': 'sentinel-3b',\n    'ANT': 'antarctica',\n    'GRE': 'greenland'\n}\n\nDefine geometries, which are the same for all items within the same region. If they are not, these have to be extracted from the assets inside the item.\n\n# Define the spatial extent (bbox) for each region of interest\ngreenland_bbox = [-74.0, 59.0, -10.0, 84.0]\ngreenland_geometry = json.loads(json.dumps(box(*greenland_bbox).__geo_interface__))\n\nantarctica_bbox = [-180.0, -90.0, 180.0, -60.0]\nantarctica_geometry = json.loads(json.dumps(box(*antarctica_bbox).__geo_interface__))\n\n\n","type":"content","url":"/creating-stac-catalog-from-prr-example#id-2-load-product-files-stored-in-esa-project-results-repository","position":9},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl3":"2.1 Group the files by the instruments, region and cycle of the dataset","lvl2":"2. Load Product files stored in ESA Project Results Repository"},"type":"lvl3","url":"/creating-stac-catalog-from-prr-example#id-2-1-group-the-files-by-the-instruments-region-and-cycle-of-the-dataset","position":10},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl3":"2.1 Group the files by the instruments, region and cycle of the dataset","lvl2":"2. Load Product files stored in ESA Project Results Repository"},"content":"\n\ndata = []\n\nfor ipath in all_item_paths:\n    splitname = ipath.split('/')[-1].split('_')\n    instrument = splitname[0]\n    cycle = splitname[9]\n    region = splitname[-2]\n\n    data.append((renaming[instrument], renaming[region], cycle, ipath))\n\n\nfiledata = pd.DataFrame(data, columns=['instrument', 'region', 'cycle', 'path'])\n\n","type":"content","url":"/creating-stac-catalog-from-prr-example#id-2-1-group-the-files-by-the-instruments-region-and-cycle-of-the-dataset","position":11},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl2":"3. Create the STAC Items with the metadata from the original files loaded from the PRR"},"type":"lvl2","url":"/creating-stac-catalog-from-prr-example#id-3-create-the-stac-items-with-the-metadata-from-the-original-files-loaded-from-the-prr","position":12},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl2":"3. Create the STAC Items with the metadata from the original files loaded from the PRR"},"content":"\n\n# group all files into items from the same instrument, region and cycle\nfor (instrument, region, cycle), links in filedata.groupby(['instrument', 'region', 'cycle']):\n    \n    # open the metadata attributes for each file in the group\n    datasets = [xr.open_dataset(root_url + link + '#mode=bytes') for link in links['path']]\n\n\n    # Define the Temporal extent\n    first_item = datasets[0]\n    last_item = datasets[-1]\n    props = first_item.attrs\n    props2 = last_item.attrs\n\n    start_datetime = props.get(\"first_meas_time\")\n    end_datetime = props2.get(\"last_meas_time\")\n\n    # Define the geometry\n    if props['zone'] == 'Antarctica':\n        bbox = antarctica_bbox\n        geometry = antarctica_geometry\n    elif props['zone'] == 'Greenland':\n        bbox = greenland_bbox\n        geometry = greenland_geometry\n\n\n    # Shared properties\n    properties = {\n        \"start_datetime\": start_datetime,\n        \"end_datetime\": end_datetime,\n        \"created\": props.get(\"processing_date\"),\n        \"description\": f\"Sentinel-3 AMPLI Land Ice Level-2 product acquired by {instrument.capitalize()} platform derived from the SRAL altimeter in Earth Observation mode over {region} region.\",\n        \"conventions\": props.get(\"Conventions\"),\n        \"platform_name\": props.get(\"platform_name\"),\n        \"platform_serial_identifier\": props.get(\"platform_serial_identifier\"),\n        \"altimeter_sensor_name\": props.get(\"altimeter_sensor_name\"),\n        \"operational_mode\": props.get(\"operational_mode\"),\n        \"cycle_number\": props.get(\"cycle_number\"),\n        \"netcdf_version\": props.get(\"netcdf_version\"),\n        \"product_type\": props.get(\"product_type\"),\n        \"timeliness\": props.get(\"timeliness\"),\n        \"institution\": props.get(\"institution\"),\n        \"processing_level\": props.get(\"processing_level\"),\n        \"processor_name\": props.get(\"processor_name\"),\n        \"processor_version\": props.get(\"processor_version\"),\n        \"references\": props.get(\"references\"),\n        \"zone\": props.get(\"zone\"),\n    }\n\n\n    # Create STAC item for the cycle\n    item = pystac.Item(\n        id=f\"sentinel-3{props.get(\"platform_serial_identifier\").lower()}-{props.get(\"zone\").lower()}-{cycle.lower()}\",\n        geometry=geometry,\n        bbox=bbox,\n        datetime=isoparse(start_datetime),\n        properties=properties\n    )\n\n    item.stac_version = \"1.1.0\"\n    item.stac_extensions = [\n        \"https://stac-extensions.github.io/projection/v1.1.0/schema.json\",\n        \"https://stac-extensions.github.io/raster/v1.1.0/schema.json\",\n        \"https://stac-extensions.github.io/eo/v1.1.0/schema.json\"\n    ]\n\n    item.assets = {}\n\n    # Add assets from that cycle\n    for nc_href, ds in zip(links['path'], datasets):\n\n        asset_title = ds.attrs['product_name']\n        extra_fields = {\n            \"cycle_number\": str(ds.attrs.get(\"cycle_number\")),\n            \"orbit_number\": str(ds.attrs.get(\"orbit_number\")),\n            \"relative_orbit_number\": str(ds.attrs.get(\"relative_orbit_number\")),\n            \"orbit_direction\": ds.attrs.get(\"orbit_direction\"),\n        }\n\n        item.add_asset(\n            key=asset_title,\n            asset=pystac.Asset(\n                href=nc_href,\n                media_type=\"application/x-netcdf\",\n                roles=[\"data\"],\n                extra_fields=extra_fields\n            )\n        )\n\n    # Save STAC item per cycle\n    json_filename = f\"sentinel-3{props.get(\"platform_serial_identifier\").lower()}-{props.get(\"zone\").lower()}-{cycle.lower()}.json\"\n    item.save_object(dest_href='examples/' + json_filename, include_self_link=False)\n    print(f\" Saved {json_filename}\")\n\n","type":"content","url":"/creating-stac-catalog-from-prr-example#id-3-create-the-stac-items-with-the-metadata-from-the-original-files-loaded-from-the-prr","position":13},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl3":"3.1  Import documentation","lvl2":"3. Create the STAC Items with the metadata from the original files loaded from the PRR"},"type":"lvl3","url":"/creating-stac-catalog-from-prr-example#id-3-1-import-documentation","position":14},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl3":"3.1  Import documentation","lvl2":"3. Create the STAC Items with the metadata from the original files loaded from the PRR"},"content":"\n\nimport pystac\nfrom datetime import datetime\nimport os\nfrom datetime import datetime, timezone\n\ndate_str = \"07/05/2025\"\n\n# Convert to ISO format string (YYYY-MM-DD)\niso_like_str = datetime.strptime(date_str, \"%d/%m/%Y\").strftime(\"%Y-%m-%d\")\n\n# Parse with isoparse and attach UTC timezone\ndt_utc = isoparse(iso_like_str).replace(tzinfo=timezone.utc)\n\nprint(dt_utc.isoformat())\n\n","type":"content","url":"/creating-stac-catalog-from-prr-example#id-3-1-import-documentation","position":15},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl3":"3.2  Create STAC Item for the documentation associated to the dataset","lvl2":"3. Create the STAC Items with the metadata from the original files loaded from the PRR"},"type":"lvl3","url":"/creating-stac-catalog-from-prr-example#id-3-2-create-stac-item-for-the-documentation-associated-to-the-dataset","position":16},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl3":"3.2  Create STAC Item for the documentation associated to the dataset","lvl2":"3. Create the STAC Items with the metadata from the original files loaded from the PRR"},"content":"\n\n# Basic metadata\ndoc_href = \"/d/S3_AMPLI_User_Handbook.pdf\"  # Relative or absolute href\ndoc_title = \"Sentinel-3 Altimetry over Land Ice: AMPLI level-2 Products\"\ndoc_description = \"User Handbook for Sentinel-3 Altimetry over Land Ice: AMPLI level-2 Products\"\n\n# Create STAC item\nitem = pystac.Item(\n    id=\"sentinel-3-ampli-user-handbook\",\n    geometry=None,\n    bbox=None,\n    datetime=dt_utc,\n    properties={\n        \"title\": doc_title,\n        \"description\": doc_description,\n        \"reference\": \"CLS-ENV-MU-24-0389\",\n        \"issue_n\": dt_utc.isoformat()\n    }\n)\n\n# Add asset for the PDF\nitem.add_asset(\n    key=\"documentation\",\n    asset=pystac.Asset(\n        href=doc_href,\n        media_type=\"application/pdf\",\n        roles=[\"documentation\"],\n        title=doc_title\n    )\n)\n\n# Save to file\nitem.set_self_href(\"examples/sentinel-3-ampli-user-handbook.json\")\nitem.save_object(include_self_link=False)\n\nprint(\"📄 STAC Item for documentation created: sentinel-3-ampli-user-handbook.json\")\n\n","type":"content","url":"/creating-stac-catalog-from-prr-example#id-3-2-create-stac-item-for-the-documentation-associated-to-the-dataset","position":17},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl2":"4. Generate valid STAC collection"},"type":"lvl2","url":"/creating-stac-catalog-from-prr-example#id-4-generate-valid-stac-collection","position":18},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl2":"4. Generate valid STAC collection"},"content":"Once all the assets are processed, create the parent collection for all Items created in the previous step.\n\ncollection = pystac.Collection.from_dict(\n\n{\n  \"id\": \"sentinel3-ampli-ice-sheet-elevation\",\n  \"type\": \"Collection\",\n  \"links\": [\n  ],\n  \"title\": \"Sentinel-3 AMPLI Ice Sheet Elevation\",\n  \"extent\": {\n    \"spatial\": {\n      \"bbox\": [\n        [-180, -90, 180, 90]\n      ]\n    },\n    \"temporal\": {\n      \"interval\": [\n        [\n          \"2016-06-01T00:00:00Z\",\n          \"2024-05-09T00:00:00Z\"\n        ]\n      ]\n    }\n  },\n  \"license\": \"CC-BY-4.0\",\n  \"summaries\": {\n    \"references\": [\n      \"https://doi.org/10.5194/egusphere-2024-1323\"\n    ],\n    \"institution\": [\n      \"CNES\"\n    ],\n    \"platform_name\": [\n      \"SENTINEL-3\"\n    ],\n    \"processor_name\": [\n      \"Altimeter data Modelling and Processing for Land Ice (AMPLI)\"\n    ],\n    \"operational_mode\": [\n      \"Earth Observation\"\n    ],\n    \"processing_level\": [\n      \"2\"\n    ],\n    \"processor_version\": [\n      \"v1.0\"\n    ],\n    \"altimeter_sensor_name\": [\n      \"SRAL\"\n    ]\n  },\n  \"description\": \"Ice sheet elevation estimated along the Sentinel-3 satellite track, as retrieved with the Altimeter data Modelling and Processing for Land Ice (AMPLI). The products cover Antarctica and Greenland.\",\n  \"stac_version\": \"1.1.0\"\n}\n)\ncollection\n\n","type":"content","url":"/creating-stac-catalog-from-prr-example#id-4-generate-valid-stac-collection","position":19},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl3":"4.1. Add items to collection","lvl2":"4. Generate valid STAC collection"},"type":"lvl3","url":"/creating-stac-catalog-from-prr-example#id-4-1-add-items-to-collection","position":20},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl3":"4.1. Add items to collection","lvl2":"4. Generate valid STAC collection"},"content":"Once the collection is created read all the items from disk and add the necassary links.\n\nimport glob\nfor fpath in glob.glob('examples/*'):\n    collection.add_item(pystac.Item.from_file(fpath))\n\n","type":"content","url":"/creating-stac-catalog-from-prr-example#id-4-1-add-items-to-collection","position":21},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl3":"4.2 Save the normalised collection","lvl2":"4. Generate valid STAC collection"},"type":"lvl3","url":"/creating-stac-catalog-from-prr-example#id-4-2-save-the-normalised-collection","position":22},{"hierarchy":{"lvl1":"Creating STAC Catalog from the PRR - Example from SRAL Processing over Land Ice Dataset","lvl3":"4.2 Save the normalised collection","lvl2":"4. Generate valid STAC collection"},"content":"\n\n# save the full self-contained collection\ncollection.normalize_and_save(\n    root_href='../data/example_catalog_ampli/',\n    catalog_type=pystac.CatalogType.SELF_CONTAINED\n)","type":"content","url":"/creating-stac-catalog-from-prr-example#id-4-2-save-the-normalised-collection","position":23},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview"},"type":"lvl1","url":"/prr-stac-download-example","position":0},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview"},"content":"This notebook has been created to support the access to the users of EarthCODE and APEX, who would like to exploit available products and project results stored in the \n\nESA Project Results Repository (PRR). PRR provides access to data, workflows, experiments and documentation from ESA EOP-S Projects organised across Collections, accessible via \n\nOGC Records e S\n\nTAC API.\n\nEach collection contains \n\nSTAC Items, with their related assets stored within the PRR storage.\n\nScientists/commercial companies can access the PRR via the \n\nEarthCODE and \n\nAPEx projects.\n\nUse following notebook cells to preview the content of the ESA PRR and request the download of selected products.\n\n","type":"content","url":"/prr-stac-download-example","position":1},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview","lvl3":"Loading Libraries and set up logging level"},"type":"lvl3","url":"/prr-stac-download-example#loading-libraries-and-set-up-logging-level","position":2},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview","lvl3":"Loading Libraries and set up logging level"},"content":"\n\nimport os\nimport logging\nimport pprint\nimport shutil\nfrom urllib.parse import urljoin\nfrom urllib.request import urlretrieve\n\n#Make sure you have installed pystac_client before running this\nfrom pystac_client import Client\n\n# set pystac_client logger to DEBUG to see API calls\nlogging.basicConfig()\nlogger = logging.getLogger(\"pystac_client\")\nlogger.setLevel(logging.DEBUG)\n\n\n","type":"content","url":"/prr-stac-download-example#loading-libraries-and-set-up-logging-level","position":3},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview","lvl3":"Connect to ESA PRR Catalog and display the list of collections available"},"type":"lvl3","url":"/prr-stac-download-example#connect-to-esa-prr-catalog-and-display-the-list-of-collections-available","position":4},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview","lvl3":"Connect to ESA PRR Catalog and display the list of collections available"},"content":"\n\n# URL of the STAC Catalog to query\ncatalog_url = \"https://eoresults.esa.int/stac\"\n\n# custom headers\nheaders = []\n\ncat = Client.open(catalog_url, headers=headers)\ncat # display the basic informaiton about PRR Catalog in STAC Format\n\n\n\nUse the cell below to access entire list of collections available in ESA PRR.\n\ncollection_search = cat.collection_search(limit=150)\nprint(f\"Total number of collections found in ESA PRR is {collection_search.matched()}\")\n\n# Display the name of the names of collection (collection-ids) to be used to filter the colleciton of interest\nfor collection in collection_search.collections_as_dicts():\n    print(collection.get(\"id\", \"Unnamed Collection\"))\n\n\n\nAlternatively, you can display the metadata of all STAC Collections available\n\n# Or they can be displayed with their full metadata\ncollection_search = cat.collection_search(\n    datetime='2023-04-02T00:00:00Z/2024-08-10T23:59:59Z',  #this is an additional filter to be added to filter the collections based on the date.\n    limit=10\n)\nprint(f\"{collection_search.matched()} collections found\")\nprint(\"PRR available Collections\\n\")\n\nfor results in collection_search.collections_as_dicts():  # maybe this part should not display entire dic\n    pp = pprint.PrettyPrinter(depth=4)\n    pp.pprint(results)\n\n","type":"content","url":"/prr-stac-download-example#connect-to-esa-prr-catalog-and-display-the-list-of-collections-available","position":5},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview","lvl3":"Open Sentinel-3 AMPLI Ice Sheet Elevation collection"},"type":"lvl3","url":"/prr-stac-download-example#open-sentinel-3-ampli-ice-sheet-elevation-collection","position":6},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview","lvl3":"Open Sentinel-3 AMPLI Ice Sheet Elevation collection"},"content":"\n\nTo access specific collection, we will use the collection id from the cell above. Type sentinel3-ampli-ice-sheet-elevation to connect to selected collection and display its metadata.\n\ncollection = cat.get_collection(\"sentinel3-ampli-ice-sheet-elevation\") # place here the id of the selected collection\n#collection # or use simply json metadata to display the information \nprint(\"PRR Sentinel-3 AMPLI Collection\\n\")\npp = pprint.PrettyPrinter(depth=4)\npp.pprint(collection.to_dict())\n\n#Or display it in the STAC file format to better visualise the attributes and properties \ncollection\n\n\n\nFrom the cell below, we will retrieve and explore queryable fields from a STAC API, which allows us to understand what parameters we can use for filtering our searches.\n\nqueryable = collection.get_queryables()\n\npp = pprint.PrettyPrinter(depth=4)\npp.pprint(queryable)\n\n","type":"content","url":"/prr-stac-download-example#open-sentinel-3-ampli-ice-sheet-elevation-collection","position":7},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview","lvl3":"Display STAC Items from Sentinel-3 AMPLI Ice Sheet Elevation collection"},"type":"lvl3","url":"/prr-stac-download-example#display-stac-items-from-sentinel-3-ampli-ice-sheet-elevation-collection","position":8},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview","lvl3":"Display STAC Items from Sentinel-3 AMPLI Ice Sheet Elevation collection"},"content":"\n\nBy executing the cell below you will get the ids of items that can be found in the specific collection (requested above).\nFirst five items from the list are printed out.\n\nitems = collection.get_items()\n\n# flush stdout so we can see the exact order that things happen\ndef get_five_items(items):\n    for i, item in enumerate(items):\n        print(f\"{i}: {item}\", flush=True)\n        if i == 4:\n            return\n        \nprint(\"First page\", flush=True)\nget_five_items(items)\n\nprint(\"Second page\", flush=True)\nget_five_items(items)\n\nNow execute a search with a set of parameters. In this case it returns just one item because we filter on one queryable parameter (id)\n\n#Search for items based on spatio-temporal properties\n\n# AOI entire world\ngeom = {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n        [\n            [-180, -90],\n            [-180, 90],\n            [180 , 90],\n            [180, -90],\n            [-180, -90],\n        ]\n    ],\n}\n\n# limit sets the # of items per page so we can see multiple pages getting fetched\n#In this search we apply also filtering on ID that is one of the searchable parameters for the colletion\nsearch = cat.search(\n    max_items=7,\n    limit=5,\n    collections=\"sentinel3-ampli-ice-sheet-elevation\",        # specify collection id\n    intersects=geom,\n    query={\"id\": {\"eq\": \"sentinel-3a-antarctica-cycle107\"}},  # search for the specific Item in the collection \n    datetime=\"2023-04-02T00:00:00Z/2024-08-10T23:59:59Z\",     # specify the start and end date of the time frame to perform the search \n)\n\nitems = list(search.items())\n\nprint(len(items))\n\npp = pprint.PrettyPrinter(depth=4)\npp.pprint([i.to_dict() for i in items])\n\n\n\nIf you do not know the item id, search through available satellite instrument name, region, number of the cycle and the datetime range of the products of interest. \nYou can specify them by filtering based on following possible values: \n\nmissions: 3a or 3b\n\nregions: anarctica or greenland\n\ncycle range: for sentinel-3a possible cycle range is from 005 to 112; while sentinel-3b has range from 011-093\n\ndatetime: specify the time frame of the products from the range between: 2016-06-01 00:00:00 UTC – 2024-05-09 00:00:00 UTC \n\n#Search for items from specific mission and type of the instrument (based on the id) and the region as well as cycle number \n# Define your cycle range and mission types\ncycle_range = [f\"{i:03d}\" for i in range(90, 111)] #005 to 111   # for sentinel-3a possible cycle range is from 005 to 111; while s3b has range from 011-092\nmissions = [\"3b\"]          # select the mission and sensor type from:\"sentinel-3a\" or \"sentinel-3b\"]  \nregions = [\"antarctica\"]              # specify the region from: \"antarctica\" or \"greenland\"\n\n# AOI entire world\ngeom = {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n        [\n            [-180, -90],\n            [-180, 90],\n            [180 , 90],\n            [180, -90],\n            [-180, -90],\n        ]\n    ],\n}\n\n# limit sets the # of items per page so we can see multiple pages getting fetched\n#In this search we apply also filtering on ID that is one of the searchable parameters for the colletion\nsearch = cat.search(\n    max_items=7,\n    limit=5,\n    collections=\"sentinel3-ampli-ice-sheet-elevation\",\n    intersects=geom,  # search for the specific Item in the collection \n    datetime=\"2021-04-02T00:00:00Z/2024-08-10T23:59:59Z\",     # specify the start and end date of the time frame to perform the search which are: 2016-06-01 00:00:00 UTC – 2024-05-09 00:00:00 UTC\n)\nitems = list(search.items())\nprint(f\"Number of items found: {len(items)}\")\nprint(items)\n\npp = pprint.PrettyPrinter(depth=4)\n\nfiltered = [\n    item for item in items\n    if any(m in item.id.lower()  for m in missions)\n    and any(r in item.id.lower()  for r in regions)\n    and any(f\"cycle{c}\" in item.id.lower() for c in cycle_range)\n]\n\n\n#for i, item in enumerate(filtered, 2):\n   # print(f\"{i}. {item.id} @ {item.datetime}\")\n\n## Print number of filtered items\nprint(f\"Number of filtered items: {len(filtered)}\")\nfor i, item in enumerate(filtered, 2):\n    print(f\"{i}. {item.id} @ {item.datetime}\")\n\n","type":"content","url":"/prr-stac-download-example#display-stac-items-from-sentinel-3-ampli-ice-sheet-elevation-collection","position":9},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview","lvl2":"Download all assets from the selected item "},"type":"lvl2","url":"/prr-stac-download-example#download-all-assets-from-the-selected-item","position":10},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview","lvl2":"Download all assets from the selected item "},"content":"Based on the selection done in the previous cell, download the products to the downloads folder in your workspace\n\nbase_url = \"https://eoresults.esa.int\"\n\nitem_to_be_downloaded = 3\ntarget = items[item_to_be_downloaded]\n\noutput_dir = f\"downloads/{target.id}\"\nos.makedirs(output_dir, exist_ok=True)\n\nassets_total=len(target.assets.items())\nassets_current=0\nfor asset_key, asset in target.assets.items():\n    filename = os.path.basename(asset.href)\n    full_href = urljoin(base_url, asset.href)\n    local_path = os.path.join(output_dir, filename)\n    assets_current+=1\n    print(f\"[{assets_current}/{assets_total}] Downloading {filename}...\")\n    try:\n        urlretrieve(full_href, local_path)\n    except Exception as e:\n        print(f\"Failed to download {full_href}. {e}\")\n\n\n","type":"content","url":"/prr-stac-download-example#download-all-assets-from-the-selected-item","position":11},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview","lvl2":"Download filtered items "},"type":"lvl2","url":"/prr-stac-download-example#download-filtered-items","position":12},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview","lvl2":"Download filtered items "},"content":"Based on the selection done in the previous cell, download the products to the downloads folder in your workspace. You will download here the items which result from further filtering options (by mission type, cycle number, region etc.)\n\ntarget = filtered[0] if len(filtered) > 0 else None\n\noutput_dir = f\"downloads/{target.id}\"\nos.makedirs(output_dir, exist_ok=True)\n\nassets_total=len(target.assets.items())\nassets_current=0\nfor asset_key, asset in target.assets.items():\n    filename = os.path.basename(asset.href)\n    full_href = urljoin(base_url, asset.href)\n    local_path = os.path.join(output_dir, filename)\n    assets_current+=1\n    print(f\"[{assets_current}/{assets_total}] Downloading {filename}...\")\n    try:\n        urlretrieve(full_href, local_path)\n    except Exception as e:\n        print(f\"Failed to download {full_href}. {e}\")     \n\nbase_url = \"https://eoresults.esa.int\"\nfor index, item in enumerate(filtered, 2):\n    output_dir = f\"filtered/{item.id}\"\n    os.makedirs(output_dir, exist_ok=True)\n\n    assets_total = len(item.assets.items())\n    assets_current = 0\n\n    for asset_key, asset in item.assets.items():\n        filename = os.path.basename(asset.href)\n        full_href = urljoin(base_url, asset.href)\n        local_path = os.path.join(output_dir, filename)\n\n        assets_current += 1\n        print(f\"[{index}] [{assets_current}/{assets_total}] Downloading {filename} for item {item.id}...\")\n\n        try:\n            urlretrieve(full_href, local_path)\n        except Exception as e:\n            print(f\"Failed to download {full_href}. {e}\")\n\nprint(f\"Downloaded assets for {len(filtered)} items.\")\n\n","type":"content","url":"/prr-stac-download-example#download-filtered-items","position":13},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview","lvl2":"(Optional) Read some data to ensure all items are downloaded properly"},"type":"lvl2","url":"/prr-stac-download-example#id-optional-read-some-data-to-ensure-all-items-are-downloaded-properly","position":14},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview","lvl2":"(Optional) Read some data to ensure all items are downloaded properly"},"content":"\n\nimport xarray as xr\nimport numpy as np\n\n# change this to a downloaded file\nexample_filepath = f'./downloads/{target.id}/S3A_SR_2_TDP_LI_20240403T201315_20240403T201615_20250416T191921_0180_111_014______CNE_GRE_V001.nc'\n\n# Open selected product and check the values\n# Note: You can select another group of values to read : satellite_and_altimeter, or ESA_L2_processing\nds = xr.open_dataset(example_filepath, group='AMPLI_processing')\nvalues = ds['elevation_radar_ampli'].values\nvalues[~np.isnan(values)]\n\n","type":"content","url":"/prr-stac-download-example#id-optional-read-some-data-to-ensure-all-items-are-downloaded-properly","position":15},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview","lvl2":"(Optional) Create an archive of products downloaded"},"type":"lvl2","url":"/prr-stac-download-example#id-optional-create-an-archive-of-products-downloaded","position":16},{"hierarchy":{"lvl1":"ESA Project Results Repository (PRR) Data Access and Collections Preview","lvl2":"(Optional) Create an archive of products downloaded"},"content":"\n\nCreate an archive of the products downloaded to your workspace and save them in .zip format to make them compressed\n\n# Create an archive of downloaded products \nzip_path = shutil.make_archive(output_dir, 'zip', root_dir=output_dir)\nprint(f\"Created ZIP archive: {zip_path}\")","type":"content","url":"/prr-stac-download-example#id-optional-create-an-archive-of-products-downloaded","position":17},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR"},"type":"lvl1","url":"/prr-stac-introduction","position":0},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR"},"content":"","type":"content","url":"/prr-stac-introduction","position":1},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"Introduction"},"type":"lvl3","url":"/prr-stac-introduction#introduction","position":2},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"Introduction"},"content":"\n\nThis notebook has been created to show the core steps required of EarthCODE users to upload their research outcomes to the \n\nESA Project Results Repository (PRR). It focuses on generating metadata for a project with a single  netcdf file.\n\nPRR provides access to data, workflows, experiments and documentation from ESA Projects organised across Collections, accessible via the \n\nSTAC API. Each Collection contains \n\nSTAC Items, with their related Assets stored within the PRR storage. Scientists/commercial companies can access the PRR via the \n\nEarthCODE and \n\nAPEx projects.\n\nThe \n\nSTAC Specification, provides detailed explanation and more information on this metadata format.\n\nIn order to upload data to the ESA Project Results Repository (PRR) you have to generate a STAC Collection that is associated to your files. The STAC Collection provides metadata about your files and makes them searchable and machine readable. The metadata generation process is organised in four steps process:\n\nGenerate a root STAC Collection\n\nGroup your dataset files into STAC Items and STAC Assets\n\nAdd the Items to the Collection\n\nSave the normalised Collection\n\nThe easiest way to generate all the required files is to use a STAC library, such as pystac or riostac. This library will take care of creating the links and formating the files in the correct way.  In the examples below we are using pystac.\n\nHave a look at the steps below and learn how to prepare your dataset to generate a valid STAC Collection. You will find all the steps descibed in the markdown cell, together with the example code (executable) to make this process easier. Please adjust the information in the fields required to describe your Collection and Items according to the comments, starting with : “#”\n\nNOTE: Depending on the information that you put in the Assets or Items the code, you may get an error about an object not being json-serialisable. If this happens, you have to transform the problem field into an object that can be described using standard JSON. For example, transforming a numpy array into a list.\n\n","type":"content","url":"/prr-stac-introduction#introduction","position":3},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"🌊 Example: 4DATLANTIC-OHC Project"},"type":"lvl3","url":"/prr-stac-introduction#id-example-4datlantic-ohc-project","position":4},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"🌊 Example: 4DATLANTIC-OHC Project"},"content":"The code below demonstrates how to perform the necessary steps using real data from the ESA Regional Initiative Project 4DATLANTIC-OHC. The project focuses on ocean heat content and provides monthly gridded Atlantic Ocean heat content change as well as OHC trends and their uncertainties.\n\n🔗 Learn more about the project here: \n\n4DATLANTIC-OHC – EO4Society \n🔗 Check the project website: \n\n4DATLANTIC-OHC – Website","type":"content","url":"/prr-stac-introduction#id-example-4datlantic-ohc-project","position":5},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl4":"Acknowledgment","lvl3":"🌊 Example: 4DATLANTIC-OHC Project"},"type":"lvl4","url":"/prr-stac-introduction#acknowledgment","position":6},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl4":"Acknowledgment","lvl3":"🌊 Example: 4DATLANTIC-OHC Project"},"content":"We gratefully acknowledge the 4DATLANTIC-OHC project team for providing access to the data used in this example.\n\nThis example is intended to help you understand the workflow and apply similar steps to your own Earth observation data analysis. \n\n","type":"content","url":"/prr-stac-introduction#acknowledgment","position":7},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"Import necessary Python libraries"},"type":"lvl3","url":"/prr-stac-introduction#import-necessary-python-libraries","position":8},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"Import necessary Python libraries"},"content":"You can create an example conda/miniconda enviroment to run the below code using:conda create -n prr_stack_example pystac xarray shapely\nconda activate prr_stack_example\n\n# import libraries\nfrom pystac import Collection\nimport pystac\nimport xarray as xr\nimport shapely\nimport json\nfrom datetime import datetime\n\n","type":"content","url":"/prr-stac-introduction#import-necessary-python-libraries","position":9},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"1. Generate a root STAC collection"},"type":"lvl3","url":"/prr-stac-introduction#id-1-generate-a-root-stac-collection","position":10},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"1. Generate a root STAC collection"},"content":"The root STAC Collection provides a general description of the enitre dataset, that you would like to store in ESA PRR. In the STAC Specification a Collection is defined as  an extension of the STAC Catalog with additional information such as the extents, license, keywords, providers, etc that describe STAC Items that fall within the Collection. \n\nIn short: it behaves as the container to store the various Items that build up your dataset. \n\nSTAC Collection has some required fields that you need to provide in order to build its valid description. Most of these metadata fields should be extracted from your data.\nPlease have a look at the example below.{\n  \"type\": \"Collection\", # Do not change\n  \"id\": \"\", # add a unique variation of project name + dataset name \n  \"stac_version\": \"1.1.0\", # Do not change\n  \"title\": \"\", # Meaningful title of your dataset\n  \"description\": \"\", # General description of your dataset\n  \"extent\": {\n    \"spatial\": {\n      \"bbox\": [\n        [\n          -180.0,\n          -90.0,\n          180.0,\n          90.0\n        ]\n      ]\n    }, # Spatial extent of your dataset. If you have multiple data files take the minimum bounding box that covers all.\n    \"temporal\": {\n      \"interval\": [\n        [\n          \"1982-01-01T00:00:00Z\",\n          \"2022-12-31T23:59:59Z\"\n        ] # Temporal extent of your dataset. If you have multiple data files take the minimum temporal range that covers all.\n      ]\n    }\n  },\n\"license\": \"\", # the license that applies to entire dataset\n\"links\": [] # do not change\n\n}\n\n","type":"content","url":"/prr-stac-introduction#id-1-generate-a-root-stac-collection","position":11},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl5":"Example | Create Collection","lvl3":"1. Generate a root STAC collection"},"type":"lvl5","url":"/prr-stac-introduction#example-create-collection","position":12},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl5":"Example | Create Collection","lvl3":"1. Generate a root STAC collection"},"content":"\n\n# define collection id, since it will be reused\ncollectionid = \"4datlantic-ohc\"\n\n# create the root collection using pystac.Collection\n\ncollection = Collection.from_dict(\n    \n{\n  \"type\": \"Collection\",\n  \"id\": collectionid,\n  \"stac_version\": \"1.1.0\",\n  \"title\": \"Atlantic Ocean heat content change\",\n  \"description\": \"Given the major role of the Atlantic Ocean in the climate system, it is essential to characterize the temporal and spatial variations of its heat content. The OHC product results from the space geodetic approach also called altimetry-gravimetry approach. This dataset contains variables as 3D grids of ocean heat content anomalies at 1x1 resolution and monthly time step. Error variance-covariance matrices of OHC at regional scale and annual resolution are also provided. See Experimental Dataset Description for details: https://www.aviso.altimetry.fr/fileadmin/documents/data/tools/OHC-EEI/OHCATL-DT-035-MAG_EDD_V2.0.pdf.Version. V2-0 of Dataset published 2022 in Centre National d’Etudes Spatiales. This dataset has been produced within the framework of the 4DAtlantic-Ocean heat content Project funded by ESA.\",\n  \"extent\": {\n    \"spatial\": {\n      \"bbox\": [\n        [-100, \n         -90, \n         25,\n         90]\n      ]\n    },\n    \"temporal\": {\n      \"interval\": [\n        [\n          \"2002-04-15T18:07:12Z\",\n          \"2023-09-01T18:59:59Z\"\n        ]\n      ]\n    }\n  },\n  \"license\": \"Aviso License\",\n  \"links\": []\n\n}\n\n)\n\ncollection\n\n","type":"content","url":"/prr-stac-introduction#example-create-collection","position":13},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"2.  Group your dataset files into STAC Items and STAC Assets"},"type":"lvl3","url":"/prr-stac-introduction#id-2-group-your-dataset-files-into-stac-items-and-stac-assets","position":14},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl3":"2.  Group your dataset files into STAC Items and STAC Assets"},"content":"The second step is to describe the different files as Items and Assets. This is the most time-consuming step. There are multiple strategies for doing this and it is up to you to decide how to do it. The main consideration should be usability of the data.\n\nFor example:\n\nMicrosoft Planatery Computer groups its Sentinel-2 data into Items which represent individual regions, and each Item has 13 Assets each representing a band - \n\nhttps://​stacindex​.org​/catalogs​/microsoft​-pc​#​/43bjKKcJQfxYaT1ir3Ep6uENfjEoQrjkzhd2​?cp​=​1​&​t​=5 .\n\nThe California Forest Observatory (on Google Earth Engine) groups its data into Items, where each Item represents a specific year, data type and resolution for the whole study area. Each Item has only one Asset ( dataset ) associated with it - \n\nhttps://​stacindex​.org​/catalogs​/forest​-observatory​#​/4dGsSbK8F5jjmhRZYE6kjUMmgWCUKe6J2qqw​?t​=2.\n\nA More complex example from real-data from ESA-funded project: \n\nESA Projects Results Repository, gives the researchers flexibility in terms on how their datasets will be grouped into Items and Assets. You may need to consider that the more Items you have in your Collection, the slower the browsing would be if the user would like to browse through the publicly open STAC Browser. Please have a look at one example, that provides one Sentinel-3 AMPLI Ice Sheet Elevation Collection with around 400 Items complemented by around 360 Assets each.\n\n\nhttps://​eoresults​.esa​.int​/browser​/​#​/external​/eoresults​.esa​.int​/stac​/collections​/sentinel3​-ampli​-ice​-sheet​-elevation\n\nMore general examples about creating STAC catalogs are available here - \n\nhttps://​github​.com​/stac​-utils​/pystac​/tree​/main​/docs​/tutorials.\n\nThe easiest way to generate the required STAC Items is to copy over the metadata directly from your files.\n\n","type":"content","url":"/prr-stac-introduction#id-2-group-your-dataset-files-into-stac-items-and-stac-assets","position":15},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl5":"Example | Open Dataset","lvl3":"2.  Group your dataset files into STAC Items and STAC Assets"},"type":"lvl5","url":"/prr-stac-introduction#example-open-dataset","position":16},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl5":"Example | Open Dataset","lvl3":"2.  Group your dataset files into STAC Items and STAC Assets"},"content":"\n\nimport urllib.request\n\n# Download the dataset locally\nurllib.request.urlretrieve('https://data.aviso.altimetry.fr/aviso-gateway/data/indicators/OHC_EEI/4DAtlantic_OHC/OHC_4DATLANTIC_200204_202212_V2-0.nc', 'OHC_4DATLANTIC_200204_202212_V2-0.nc')\n\n\n# open dataset\n\n# define relative filepath within the folder structure you want to upload to the PRRs\nfilepath = 'OHC_4DATLANTIC_200204_202212_V2-0.nc'\n\nds = xr.open_dataset(filepath)\nds\n\n# helper function to convert numpy arrays to lists\nimport numpy as np\ndef convert_to_json_serialisable(attrs):\n    attrs = attrs.copy()\n    for attr in attrs.keys():\n        if isinstance(attrs[attr], np.ndarray):\n            attrs[attr] = attrs[attr].tolist()\n    return attrs\n\n","type":"content","url":"/prr-stac-introduction#example-open-dataset","position":17},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl5":"Example | Create valid STAC Item from your product (nc)","lvl3":"2.  Group your dataset files into STAC Items and STAC Assets"},"type":"lvl5","url":"/prr-stac-introduction#example-create-valid-stac-item-from-your-product-nc","position":18},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl5":"Example | Create valid STAC Item from your product (nc)","lvl3":"2.  Group your dataset files into STAC Items and STAC Assets"},"content":"\n\n# Describe the first file (Item)\n\n\n# 1. extract the spatial extent from the .nc file \nbbox = [ds['longitude'].values.min(), ds['latitude'].values.min(), ds['longitude'].values.max(), ds['latitude'].values.max(), ]\ngeometry = json.loads(json.dumps(shapely.box(*bbox).__geo_interface__))\n\n# 2. extract additional information (properties) from the .nc file and create the STAC Item\nitem = pystac.Item(\n    id=collectionid + 'v2',\n    geometry=geometry,\n    datetime=datetime.strptime('2025-02-05', '%Y-%m-%d'),\n    bbox=bbox,\n    properties= {\n        \"history\": ds.attrs['history'],\n        \"source\": ds.attrs['source'],\n        \"comment\": ds.attrs['comment'],\n        \"references\": ds.attrs['references'],\n        \"summary\": ds.attrs['summary'],\n        \"version\": ds.attrs['version'],\n        \"conventions\": ds.attrs['Conventions'],\n    } # please note that this field is not mandatory by STAC specification, \n        # and depends on the information you have provided within your original dataset.\n      # You are encouraged to provide as complete information as possible here, to make sure your product has rich metadata, facilitating product discoverability and usability\n)\n\n# 3. Extract variable properties at the Item level, since there is only one file\nstac_property_prefix = 'variable_'\nitem.properties[f\"{stac_property_prefix}ohc\"] = convert_to_json_serialisable(ds.variables['ohc'].attrs)\nitem.properties[f\"{stac_property_prefix}ohc_var_covar_matrix_local\"] = convert_to_json_serialisable(ds.variables['ohc_var_covar_matrix_local'].attrs)\nitem.properties[f\"{stac_property_prefix}ohc_mask\"] = convert_to_json_serialisable(ds.variables['ohc_mask'].attrs)\n\n\n# 4. Add asset\nitem.add_asset(\n            key='OHC Atlantic Dataset', # title can be arbitrary\n            asset=pystac.Asset(\n                href=f'/d/{collectionid}/{filepath}', # keep the /d/ reference\n                media_type=\"application/x-netcdf\",\n                roles=[\"data\"],\n            )\n) ## Please note that asset can describe a satllite image band, as well as single nc or tiff file, depending on the orginal data structure. \n\nitem # Preview created Item\n\n","type":"content","url":"/prr-stac-introduction#example-create-valid-stac-item-from-your-product-nc","position":19},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl2":"3. Add the STAC Item to the STAC Collection"},"type":"lvl2","url":"/prr-stac-introduction#id-3-add-the-stac-item-to-the-stac-collection","position":20},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl2":"3. Add the STAC Item to the STAC Collection"},"content":"Adding the Items to the Collection is a single function call when using a library such as pystac.\n\ncollection.add_item(item)\n\n","type":"content","url":"/prr-stac-introduction#id-3-add-the-stac-item-to-the-stac-collection","position":21},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl2":"4. Save the Collection"},"type":"lvl2","url":"/prr-stac-introduction#id-4-save-the-collection","position":22},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl2":"4. Save the Collection"},"content":"Again this step is a single function call.\n\ncollection.normalize_and_save(\n    root_href='example_4datlantic/', # path to the self-contained folder with STAC Collection\n    catalog_type=pystac.CatalogType.SELF_CONTAINED\n)\n\ncollection\n\n","type":"content","url":"/prr-stac-introduction#id-4-save-the-collection","position":23},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl5":"Congratulations, you have created your first STAC Collection. ","lvl2":"4. Save the Collection"},"type":"lvl5","url":"/prr-stac-introduction#congratulations-you-have-created-your-first-stac-collection","position":24},{"hierarchy":{"lvl1":"Generating a STAC Collection for the PRR","lvl5":"Congratulations, you have created your first STAC Collection. ","lvl2":"4. Save the Collection"},"content":"Now, you have your results ready to be ingested into ESA PRR. To request data storage in ESA PRR, contact EarthCODE team at: \n\nearth-code@esa.int and provide following information:\n\nyour project name\n\ntotal size of your dataset\n\nlink to STAC Collection created together with associated Items (e.g. entire example_4datlantic folder) - can be provided as a .zip or link to online repository / GitHub public repository\n\nlink to the datasets (access link to final outcomes of the project or assets)\n\nspecify any restrictions related to the access of your dataset.\n\nin the email, do not forget to CC your ESA TO to acknowledge that the dataset will be imported into PRR.\n\nOnce the email is received, the EarthCODE team will make a request to publish your product into PRR on your behalf (in the future the self-ingestion system will be supported).\n\nOnce the collection is imported you will receive a dedicated URL to your products, which you can use to create the record on Open Science Data Catalogue to make your data discoverable or/and request a DOI for your dataset (at the moment this has to be done by external service of your choice).","type":"content","url":"/prr-stac-introduction#congratulations-you-have-created-your-first-stac-collection","position":25},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets"},"type":"lvl1","url":"/example-tccas","position":0},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets"},"content":"This notebook shows how to generate a valid STAC collection, which is a requirement to upload research outcomes to the \n\nESA Project Results Repository (PRR). It focuses on generating metadata for a project with a multiple data files of different types.\n\nCheck the \n\nEarthCODE documentation, and \n\nPRR STAC introduction example for a more general introduction to STAC and the ESA PRR.\n\nThe code below demonstrates how to perform the necessary steps using real data from the ESA project Terrestrial Carbon Community Assimilation System (TCCAS). The focus of TCCAS is the combination of a diverse array of observational data streams with the D&B terrestrial biosphere model into a consistent picture of the terrestrial carbon, water, and energy cycles.\n\n🔗 Check the project website: \n\nTerrestrial Carbon Community Assimilation System (TCCAS) – Website\n\n🛢️ TCCAS Dataset: \n\nTerrestrial Carbon Community Assimilation System (TCCAS) – Data base: Sodankylä and Lapland region","type":"content","url":"/example-tccas","position":1},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets","lvl3":"Acknowledgment"},"type":"lvl3","url":"/example-tccas#acknowledgment","position":2},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets","lvl3":"Acknowledgment"},"content":"We gratefully acknowledge the Terrestrial Carbon Community Assimilation System (TCCAS) team for providing access to the data used in this example, as well as support in creating it.\n\n# import libraries\nimport xarray as xr\nfrom pystac import Item, Collection\nimport pystac\nfrom datetime import datetime\nfrom shapely.geometry import box, mapping\nimport glob\nimport json\nimport shapely\nimport numpy as np\n\n","type":"content","url":"/example-tccas#acknowledgment","position":3},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets","lvl2":"1. Generate the parent collection"},"type":"lvl2","url":"/example-tccas#id-1-generate-the-parent-collection","position":4},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets","lvl2":"1. Generate the parent collection"},"content":"The root STAC Collection provides a general description of all project outputs which will be stored on the PRR.\nThe PRR STAC Collection template enforces some required fields that you need to provide in order to build its valid description. Most of these metadata fields should already be available and can be extracted from your data.\n\n# create the parent collection\ncollectionid = \"tccas-sodankylae\"\n\n\ncollection = Collection.from_dict(\n    \n{\n  \"type\": \"Collection\",\n  \"id\": collectionid,\n  \"stac_version\": \"1.1.0\",\n  \"title\": \"Terrestrial Carbon Community Assimilation System: Database for Lapland and Sodankyla region\",\n  \"description\": \"The Terrestrial Carbon Community Assimilation System (TCCAS) is built around the coupled D&B terrestrial biosphere model. D&B has been newly developed based on the well-established DALEC and BETHY models and builds on the strengths of each component model. In particular, D&B combines the dynamic simulation of the carbon pools and canopy phenology of DALEC with the dynamic simulation of water pools, and the canopy model of photosynthesis and energy balance of BETHY. D&B includes a set of observation operators for optical as well as active and passive microwave observations. The focus of TCCAS is the combination of this diverse array of observational data streams with the D&B model into a consistent picture of the terrestrial carbon, water, and energy cycles. TCCAS applies a variational assimilation approach that adjusts a combination of initial pool sizes and process parameters to match the observational data streams. This dataset includes Satelite, Field and model forcing data sets for Sodankylä and Lapland region.\",\n  \"extent\": {\n    \"spatial\": {\n      \"bbox\": [\n        [\n          18.00,\n          65.00,\n          32.00,\n          69.00\n        ]\n      ]\n    },\n    \"temporal\": {\n      \"interval\": [\n        [\n          \"2011-01-01T00:00:00Z\",\n          \"2021-12-31T00:00:00Z\"\n        ]\n      ]\n    }\n  },\n  \"license\": \"various\",\n  \"links\": []\n\n}\n\n)\n\ncollection # visualise the metadata of your collection \n\n","type":"content","url":"/example-tccas#id-1-generate-the-parent-collection","position":5},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets","lvl2":"2. Create STAC Items and STAC Assets from original dataset"},"type":"lvl2","url":"/example-tccas#id-2-create-stac-items-and-stac-assets-from-original-dataset","position":6},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets","lvl2":"2. Create STAC Items and STAC Assets from original dataset"},"content":"The second step is to describe the different files as STAC Items and Assets. Take your time to decide how your data should be categorised to improve usability of the data, and ensure intuitive navigation through different items in the collections. There are multiple strategies for doing this and this tutorial demonstrate one of the possible ways of doing that. Examples of how other ESA projects are doing this are available in the \n\nEarthCODE documentation\n\n","type":"content","url":"/example-tccas#id-2-create-stac-items-and-stac-assets-from-original-dataset","position":7},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets","lvl3":"2.1 Create STAC Item from Satellite Dataset","lvl2":"2. Create STAC Items and STAC Assets from original dataset"},"type":"lvl3","url":"/example-tccas#id-2-1-create-stac-item-from-satellite-dataset","position":8},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets","lvl3":"2.1 Create STAC Item from Satellite Dataset","lvl2":"2. Create STAC Items and STAC Assets from original dataset"},"content":"\n\n# define dataset names and base url. If the data is locally stored, then you have to adjust these paths.\n\n\nroot_url = 'https://lcc.inversion-lab.com/data/eo/'\ndata_files = {\n    \"Fraction of absorbed Photosynthetic Active Radiation Leaf Area Index (JRC-TIP)\": \"/jrc-tip/jrctip_fapar-lai_sodankyla_20110101-20220105.nc\",\n    \"Brightness temperature (SMOS TB)\": \"smos/smos_l3tb/SMOS_L3TB__sodankyla.nc\",\n    \"Soil moisture and Vegetation Optical Depth (SMOS SM and SMOS L-VOD)\": \"smos/smosL2/smosL2_1D_v700_sodankyla_trans.nc\",\n    \"Solar Induced Chlorophyll Fluorescence (Sentinel 5P)\": \"sif/tropomi/Sodankyla_SIF_TROPOMI_final.nc4\",\n    \"Slope (ASCAT Slope)\": \"ascat/local_slope.final/ASCAT_slope_so.nc\",\n    \"Photochemical Reflectance Index (MODIS PRI)\": \"modis/final/PRI_ESTIMATE_SODANKYLA_SINUSOIDAL.nc\",\n    \"Land Surface Temperature (MODIS LST)\": \"modis/final/LST_ESTIMATE_SODANKYLA_SINUSOIDAL.nc\",\n    \"Solar Induced Chlorophyll Fluorescence (OCO-2 SIF)\": \"sif/oco2/Sodankyla_SIF_OCO2_final.nc4\",\n    \"Vegetation Optical Depth (AMSR-2 VOD)\": \"amsr2/final/AMSR2_so.nc\"\n} \n\n# fix the same bbox and geometry for all items in the region\nbbox = [18.00, 65.00, 32.00, 69.00]\ngeometry = json.loads(json.dumps(shapely.box(*bbox).__geo_interface__))\n\n# some attributes extracted from xarray are not json serialisable and have to be cast to other types.\ndef convert_to_json_serialisable(attrs):\n    attrs = attrs.copy()\n    for attr in attrs.keys():\n        if isinstance(attrs[attr], np.ndarray):\n            attrs[attr] = attrs[attr].tolist()\n        elif str(type(attrs[attr])).__contains__('numpy.int'):\n            attrs[attr] = int(attrs[attr])\n    return attrs\n\n# for each dataset create an item\nfor dataset_name, dataset_filepath in data_files.items():\n\n    # 1. open the netcdf file\n    ds = xr.open_dataset(root_url + dataset_filepath + '#mode=bytes')\n\n    if 'time' in ds.coords:\n        start_time = ds['time'][0].values\n        ts = (start_time - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')\n        start_time = datetime.fromtimestamp(ts)\n    elif 'yymmddHH' in ds.variables:\n        string_date = '-'.join(ds['yymmddHH'][0].values.astype(str)[:3])\n        start_time = datetime.strptime(string_date, '%Y-%m-%d')\n    else:\n        string_date = '-'.join(ds['yymmddHHMMSS'][0].values.astype(int).astype(str)[:3])\n        start_time = datetime.strptime(string_date, '%Y-%m-%d')\n\n    # 3. Create a STAC item with the extracted properties\n    item = Item(\n        id=f\"{collection.id}-{dataset_name.lower().replace(' ', '_')}\",\n        geometry=geometry,\n        datetime=start_time,\n        bbox=bbox,\n        properties= {\n            \"license\": ds.attrs['license'],\n            \"description\": f'Dataset with variables related to {dataset_name}.',\n        }\n    )\n\n    if len(item.properties['license']) > 20:\n        item.properties['license'] = 'TIP-FAPAR-1.7'\n\n    # 3. add an asset (the actual link to the file)\n    item.add_asset(\n                key=f'Dataset with variables related to {dataset_name}.', # title can be arbitrary\n                asset=pystac.Asset(\n                    href=f'/d/{collectionid}/{dataset_filepath.split('/')[-1]}',\n                    media_type=\"application/x-netcdf\",\n                    roles=[\"data\"],\n                )\n    )\n\n    # 4. Extract variable information\n    for v in ds.variables:\n        item.properties[f\"variable_{v}\"] = convert_to_json_serialisable(ds.variables[v].attrs)\n\n    item.validate()\n\n    # 5. Add the item to the collection\n    collection.add_item(item)\n    \n\n","type":"content","url":"/example-tccas#id-2-1-create-stac-item-from-satellite-dataset","position":9},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets","lvl3":"2.2 Create STAC Item from In situ Dataset","lvl2":"2. Create STAC Items and STAC Assets from original dataset"},"type":"lvl3","url":"/example-tccas#id-2-2-create-stac-item-from-in-situ-dataset","position":10},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets","lvl3":"2.2 Create STAC Item from In situ Dataset","lvl2":"2. Create STAC Items and STAC Assets from original dataset"},"content":"\n\n# add a single item with all the in-situ data, since it comes in a single .tgz file\nitem = Item(\n    id=f\"{collection.id}-insitu_package\",\n    geometry=geometry,\n    datetime=start_time,\n    bbox=bbox,\n    properties= {\n        \"license\": \"CC-BY-4.0\",\n        \"description\": 'Insitu package with FloX, VOD and Miscellaneous field datasets related to the TCCAS project. ',\n    }\n)\n\n# 3. add an asset (the actual link to the file)\nitem.add_asset(\n            key=f'Insitu package', # title can be arbitrary\n            asset=pystac.Asset(\n                href=f'/d/{collectionid}/sodankyla-insitu-package.tgz',\n                media_type=\"application/tar+gzip\",\n                roles=[\"data\"],\n            )\n)\n\nitem.validate()\ncollection.add_item(item)\n\n","type":"content","url":"/example-tccas#id-2-2-create-stac-item-from-in-situ-dataset","position":11},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets","lvl3":"2.3 Create STAC Item from Model based Dataset","lvl2":"2. Create STAC Items and STAC Assets from original dataset"},"type":"lvl3","url":"/example-tccas#id-2-3-create-stac-item-from-model-based-dataset","position":12},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets","lvl3":"2.3 Create STAC Item from Model based Dataset","lvl2":"2. Create STAC Items and STAC Assets from original dataset"},"content":"\n\n# add an item with multiple model forcing assets\nitem = Item(\n    id=f\"{collectionid}-model_forcing\",\n    geometry=geometry,\n    datetime=start_time,\n    bbox=bbox,\n    properties= {\n        \"license\": \"CC-BY-4.0\",\n        \"description\": ' Regional and Site-level model forcing Data Sets for Sodankylä and Lapland region, part of the TCCAS project.',\n    }\n)\n\n\n# 3. add an asset (the actual link to the file)\nitem.add_asset(\n            key=f'static-site-level', # title can be arbitrary\n            asset=pystac.Asset(\n                href=f'/d/{collectionid}/FI-Sod_staticforcing.nc',\n                media_type=\"application/x-netcdf\",\n                roles=[\"data\"],\n            )\n)\n\nitem.add_asset(\n            key=f'time-dependent (ERA5) - site level', # title can be arbitrary\n            asset=pystac.Asset(\n                href=f'/d/{collectionid}/FI-Sod_dynforcing-era5_20090101-20211231_with-lwdown.nc',\n                media_type=\"application/x-netcdf\",\n                roles=[\"data\"],\n            )\n)\n\nitem.add_asset(\n            key=f'time-dependent (in-situ) - site level', # title can be arbitrary\n            asset=pystac.Asset(\n                href=f'/d/{collectionid}/FI-Sod_dynforcing-insitu_20090101-20211231_with-insitu-lwdown.nc',\n                media_type=\"application/x-netcdf\",\n                roles=[\"data\"],\n            )\n)\n\nitem.add_asset(\n            key=f'static-regional', # title can be arbitrary\n            asset=pystac.Asset(\n                href=f'/d/{collectionid}/sodankyla-region_cgls-pft-crops-redistributed_staticforcing.nc',\n                media_type=\"application/x-netcdf\",\n                roles=[\"data\"],\n            )\n)\n\nitem.add_asset(\n            key=f'time-dependent (ERA5) - regional', # title can be arbitrary\n            asset=pystac.Asset(\n                href=f'/d/{collectionid}/sodankyla-region_dynforcing_era5_2009-2021.nc',\n                media_type=\"application/x-netcdf\",\n                roles=[\"data\"],\n            )\n)\n\nitem.validate()\ncollection.add_item(item)\n\n","type":"content","url":"/example-tccas#id-2-3-create-stac-item-from-model-based-dataset","position":13},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets","lvl3":"2.4 Create STAC Item for the documentation and add to the Collection","lvl2":"2. Create STAC Items and STAC Assets from original dataset"},"type":"lvl3","url":"/example-tccas#id-2-4-create-stac-item-for-the-documentation-and-add-to-the-collection","position":14},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets","lvl3":"2.4 Create STAC Item for the documentation and add to the Collection","lvl2":"2. Create STAC Items and STAC Assets from original dataset"},"content":"\n\n# add all the documentation under a single item\nitem = Item(\n    id=f\"{collectionid}-documentation\",\n    geometry=geometry,\n    datetime=start_time,\n    bbox=bbox,\n    properties= {\n        \"license\": \"CC-BY-4.0\",\n        \"description\": 'Documentation for the TCCAS project datasets.',\n    }\n)\n\nitem.add_asset(\n            key=f'TCCAS user manual.', # title can be arbitrary\n            asset=pystac.Asset(\n                href=f'/d/{collectionid}/TCCAS_manual.pdf',\n                media_type=\"application/pdf\",\n                roles=[\"documentation\"],\n            )\n)\n\nitem.add_asset(\n            key=\"Satellite Data Uncertainty analysis Scientific Report\", # title can be arbitrary\n            asset=pystac.Asset(\n                href=f'/d/{collectionid}/D7.pdf',\n                media_type=\"application/pdf\",\n                roles=[\"documentation\"],\n            )\n)\n\nitem.add_asset(\n            key=\"Campaign Data User Manual\", # title can be arbitrary\n            asset=pystac.Asset(\n                href=f'/d/{collectionid}/D11_CDUM-all_sites.pdf',\n                media_type=\"application/pdf\",\n                roles=[\"documentation\"],\n            )\n)\n\ncollection.add_item(item)\n\n","type":"content","url":"/example-tccas#id-2-4-create-stac-item-for-the-documentation-and-add-to-the-collection","position":15},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets","lvl2":"4. Save the metadata as a self-contained collection"},"type":"lvl2","url":"/example-tccas#id-4-save-the-metadata-as-a-self-contained-collection","position":16},{"hierarchy":{"lvl1":"ESA Project Results Repository: Generating STAC collections with multiple assets","lvl2":"4. Save the metadata as a self-contained collection"},"content":"\n\n# save the full self-contained collection\ncollection.normalize_and_save(\n    root_href='./data/example_catalog/',\n    catalog_type=pystac.CatalogType.SELF_CONTAINED\n)\n\ncollection","type":"content","url":"/example-tccas#id-4-save-the-metadata-as-a-self-contained-collection","position":17},{"hierarchy":{"lvl1":"ESA Project Results Repository"},"type":"lvl1","url":"/index-1","position":0},{"hierarchy":{"lvl1":"ESA Project Results Repository"},"content":"The \n\nESA Project Results Repository (PRR) provides long term storage for research outcomes. It provides access to data, workflows, experiments and documentation from ESA Projects organised across Collections, accessible via the \n\nSTAC API. Each Collection contains \n\nSTAC Items, with their related Assets stored within the PRR storage. Scientists/commercial companies can access the PRR via the \n\nEarthCODE and \n\nAPEx projects.","type":"content","url":"/index-1","position":1},{"hierarchy":{"lvl1":"ESA Project Results Repository","lvl2":"Uploading data to the PRR"},"type":"lvl2","url":"/index-1#uploading-data-to-the-prr","position":2},{"hierarchy":{"lvl1":"ESA Project Results Repository","lvl2":"Uploading data to the PRR"},"content":"In order to upload data to the ESA Project Results Repository (PRR) you have to generate a STAC Collection that is associated to your files. The STAC Collection provides metadata about your files and makes them searchable and machine readable. The metadata generation process is organised in four steps process:\n\nGenerate a root STAC Collection\n\nGroup your dataset files into STAC Items and STAC Assets\n\nAdd the Items to the Collection\n\nSave the normalised Collection\n\nSend the data, metadata and some extra information to the EarthCODE team.\n\nBelow you will find guides to the whole process, we recomend starting with the introductory notebook.\n\nGenerating a STAC Collection for the PRR(Introduction) - A notebook explaining how to create the required PRR metadata. It describes the steps in detail and uses a relatively simple example, with a single .nc raster data file.\n\nGenerating a STAC Collection for the PRR (Multiple file types) - Example how to generate metadata for a more complicated dataset which has multiple types of data and different file formats.\n\nGenerating a STAC Collection for the PRR(Large dataset for multiple regions) - Example how to generate metadata for a large dataset that has multiple disjoint regions.\n\nIf you are interested in exploring/downloading PRR data you can use this notebook as a guide:\n\nESA Project Results Repository (PRR) Data Access and Collections Preview - A notebook explaining how Item Catalogs should be created, uses raster data.","type":"content","url":"/index-1#uploading-data-to-the-prr","position":3},{"hierarchy":{"lvl1":"EarthCODE Examples"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"EarthCODE Examples"},"content":"Welcome to the EarthCODE examples book!\n\nHere you will find guides and examples on how to use the various EarthCODE resources.\n\nIf you are looking to upload data to the ESA Project Results (PRR) repository, check out our \n\nPRR Examples.\n\nIf you are looking to add information to the Open Science Catalog, check out our \n\nOpen Science Catalog Examples.","type":"content","url":"/","position":1}]}