{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bead50f2-482d-4bd6-a892-8ec1ff6d705c",
   "metadata": {},
   "source": [
    "# Example from SRAL Processing over Land Ice Dataset\n",
    "\n",
    "**This is an example notebook for creating the STAC Items uploaded to ESA Project Results Repository and made available at**: https://eoresults.esa.int/browser/#/external/eoresults.esa.int/stac/collections/sentinel3-ampli-ice-sheet-elevation\n",
    "\n",
    "Dataset is also discoverable via Open Science Catalogue, providing access to created in this tutorial collection stored in ESA Project Results Repository (PRR). \n",
    "https://opensciencedata.esa.int/products/sentinel3-ampli-ice-sheet-elevation/collection \n",
    "\n",
    "It focuses on generating metadata for a project with a hundreads of items, each of which has hundreads of `netcdf` assets.\n",
    "\n",
    "Check the [EarthCODE documentation](https://earthcode.esa.int/), and [PRR STAC introduction example](https://esa-earthcode.github.io/examples/prr-stac-introduction) for a more general introduction to STAC and the ESA PRR.\n",
    "\n",
    "\n",
    "\n",
    "The code below demonstrates how to perform the necessary steps using real data from the ESA project **SRAL Processing over Land Ice\n",
    "**. With the focus of the project on improving Sentinel-3 altimetry performances over land ice.\n",
    "\n",
    "ðŸ”— Check the : [User handbook](https://eoresults.esa.int/d/sentinel3-ampli-ice-sheet-elevation/2025/05/07/sentinel-3-ampli-user-handbook/S3_AMPLI_User_Handbook.pdf)\n",
    "\n",
    "ðŸ”— Check the : [Scientifc publication](http://doi.org/https://doi.org/10.57780/s3d-83ad619)\n",
    "\n",
    "#### Acknowledgment  \n",
    "We gratefully acknowledge the **SRAL Processing over Land Ice team** for providing access to the data used in this example, as well as support in creating it.\n",
    "\n",
    "\n",
    "### Steps described in this notebook\n",
    "This notebook presents the workflow for generating a PRR Collection for the entire dataset coming from the project. To create a valid STAC Items and Collection you should follow steps described below:\n",
    "1. Generate a root STAC Collection\n",
    "2. Group your dataset files into STAC Items and STAC Assets\n",
    "3. Add the Items to the collection\n",
    "4. Save the normalised collection \n",
    "\n",
    "Due to the complexity of the project and the time it takes to process the data, the STAC Items are generated first and stored locally. They are added to the collection afterwards.\n",
    "Furthermore, since we are working with thousands of files, we are using the links from the PRR directly. When the notebook was created originally all the files were available locally.\n",
    "\n",
    "This notebook can be used as an example for following scenario(s): \n",
    "1. Creating the STAC Items from the files stored locally\n",
    "2. Creating the STAC Items from files stored in the s3bucket or other cloud repository \n",
    "3. Creating the STAC Items from files already ingested into PRR\n",
    "\n",
    "Of course if your files are locally stored, or stored in a different S3 Bucket the access to them (roor_url and items paths) should be adapted according to your dataset location. \n",
    "\n",
    "> Note: Due to the original size of the dataset ~ 100GB, running this notebook end to end may take hours. We do advise therefore to trying it on your own datasets by changing file paths to be able to produe valid STAC Collaction and STAC Items. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e929f8-1160-4f98-8be6-b5f78f88d003",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b477ae-e0a5-49a4-9544-1d7bf0fce337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pystac\n",
    "import rasterio\n",
    "from shapely import box\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "from dateutil.parser import isoparse\n",
    "from dateutil import parser\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124cdd42-d703-461f-85fd-7b21a1b0c387",
   "metadata": {},
   "source": [
    "## 2. Load Product files stored in ESA Project Results Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3cd796",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_url = 'https://eoresults.esa.int' # provide a root url for the datasets items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09af6b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all items for the S3 AMPLI collection from the PRR STAC API\n",
    "items = pystac.ItemCollection.from_file('https://eoresults.esa.int/stac/collections/sentinel3-ampli-ice-sheet-elevation/items?limit=10_000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621c47eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the paths to all the data\n",
    "\n",
    "# using a dictionary is faster than using pystac\n",
    "items_dict = items.to_dict()\n",
    "all_item_paths = []\n",
    "for item in items_dict['features']:\n",
    "    assets = item['assets']\n",
    "    for asset_name, asset_dict in assets.items():\n",
    "        if asset_dict['roles'] == ['data']:\n",
    "            all_item_paths.append(asset_dict['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27435f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of EO Missions and instruments as well as region of the dataset and cycles\n",
    "instruments = ['sentinel-3a', 'sentinel-3b']\n",
    "regions = ['antarctica', 'greenland']\n",
    "cycles = [f\"cycle{str(i).zfill(3)}\" for i in range(5, 112)]  # Cycle005 to Cycle111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7259ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the instrument name based on the acronym used in the file name\n",
    "renaming = {\n",
    "    'S3A': 'sentinel-3a',\n",
    "    'S3B': 'sentinel-3b',\n",
    "    'ANT': 'antarctica',\n",
    "    'GRE': 'greenland'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f908cb",
   "metadata": {},
   "source": [
    "Define geometries, which are the same for all items within the same region. If they are not, these have to be extracted from the assets inside the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the spatial extent (bbox) for each region of interest\n",
    "greenland_bbox = [-74.0, 59.0, -10.0, 84.0]\n",
    "greenland_geometry = json.loads(json.dumps(box(*greenland_bbox).__geo_interface__))\n",
    "\n",
    "antarctica_bbox = [-180.0, -90.0, 180.0, -60.0]\n",
    "antarctica_geometry = json.loads(json.dumps(box(*antarctica_bbox).__geo_interface__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cde8425",
   "metadata": {},
   "source": [
    "### 2.1 Group the files by the instruments, region and cycle of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for ipath in all_item_paths:\n",
    "    splitname = ipath.split('/')[-1].split('_')\n",
    "    instrument = splitname[0]\n",
    "    cycle = splitname[9]\n",
    "    region = splitname[-2]\n",
    "\n",
    "    data.append((renaming[instrument], renaming[region], cycle, ipath))\n",
    "\n",
    "\n",
    "filedata = pd.DataFrame(data, columns=['instrument', 'region', 'cycle', 'path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5686090d",
   "metadata": {},
   "source": [
    "## 3. Create the STAC Items with the metadata from the original files loaded from the PRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79789c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group all files into items from the same instrument, region and cycle\n",
    "for (instrument, region, cycle), links in filedata.groupby(['instrument', 'region', 'cycle']):\n",
    "    \n",
    "    # open the metadata attributes for each file in the group\n",
    "    datasets = [xr.open_dataset(root_url + link + '#mode=bytes') for link in links['path']]\n",
    "\n",
    "\n",
    "    # Define the Temporal extent\n",
    "    first_item = datasets[0]\n",
    "    last_item = datasets[-1]\n",
    "    props = first_item.attrs\n",
    "    props2 = last_item.attrs\n",
    "\n",
    "    start_datetime = props.get(\"first_meas_time\")\n",
    "    end_datetime = props2.get(\"last_meas_time\")\n",
    "\n",
    "    # Define the geometry\n",
    "    if props['zone'] == 'Antarctica':\n",
    "        bbox = antarctica_bbox\n",
    "        geometry = antarctica_geometry\n",
    "    elif props['zone'] == 'Greenland':\n",
    "        bbox = greenland_bbox\n",
    "        geometry = greenland_geometry\n",
    "\n",
    "\n",
    "    # Shared properties\n",
    "    properties = {\n",
    "        \"start_datetime\": start_datetime,\n",
    "        \"end_datetime\": end_datetime,\n",
    "        \"created\": props.get(\"processing_date\"),\n",
    "        \"description\": f\"Sentinel-3 AMPLI Land Ice Level-2 product acquired by {instrument.capitalize()} platform derived from the SRAL altimeter in Earth Observation mode over {region} region.\",\n",
    "        \"conventions\": props.get(\"Conventions\"),\n",
    "        \"platform_name\": props.get(\"platform_name\"),\n",
    "        \"platform_serial_identifier\": props.get(\"platform_serial_identifier\"),\n",
    "        \"altimeter_sensor_name\": props.get(\"altimeter_sensor_name\"),\n",
    "        \"operational_mode\": props.get(\"operational_mode\"),\n",
    "        \"cycle_number\": props.get(\"cycle_number\"),\n",
    "        \"netcdf_version\": props.get(\"netcdf_version\"),\n",
    "        \"product_type\": props.get(\"product_type\"),\n",
    "        \"timeliness\": props.get(\"timeliness\"),\n",
    "        \"institution\": props.get(\"institution\"),\n",
    "        \"processing_level\": props.get(\"processing_level\"),\n",
    "        \"processor_name\": props.get(\"processor_name\"),\n",
    "        \"processor_version\": props.get(\"processor_version\"),\n",
    "        \"references\": props.get(\"references\"),\n",
    "        \"zone\": props.get(\"zone\"),\n",
    "    }\n",
    "\n",
    "\n",
    "    # Create STAC item for the cycle\n",
    "    item = pystac.Item(\n",
    "        id=f\"sentinel-3{props.get(\"platform_serial_identifier\").lower()}-{props.get(\"zone\").lower()}-{cycle.lower()}\",\n",
    "        geometry=geometry,\n",
    "        bbox=bbox,\n",
    "        datetime=isoparse(start_datetime),\n",
    "        properties=properties\n",
    "    )\n",
    "\n",
    "    item.stac_version = \"1.1.0\"\n",
    "    item.stac_extensions = [\n",
    "        \"https://stac-extensions.github.io/projection/v1.1.0/schema.json\",\n",
    "        \"https://stac-extensions.github.io/raster/v1.1.0/schema.json\",\n",
    "        \"https://stac-extensions.github.io/eo/v1.1.0/schema.json\"\n",
    "    ]\n",
    "\n",
    "    item.assets = {}\n",
    "\n",
    "    # Add assets from that cycle\n",
    "    for nc_href, ds in zip(links['path'], datasets):\n",
    "\n",
    "        asset_title = ds.attrs['product_name']\n",
    "        extra_fields = {\n",
    "            \"cycle_number\": str(ds.attrs.get(\"cycle_number\")),\n",
    "            \"orbit_number\": str(ds.attrs.get(\"orbit_number\")),\n",
    "            \"relative_orbit_number\": str(ds.attrs.get(\"relative_orbit_number\")),\n",
    "            \"orbit_direction\": ds.attrs.get(\"orbit_direction\"),\n",
    "        }\n",
    "\n",
    "        item.add_asset(\n",
    "            key=asset_title,\n",
    "            asset=pystac.Asset(\n",
    "                href=nc_href,\n",
    "                media_type=\"application/x-netcdf\",\n",
    "                roles=[\"data\"],\n",
    "                extra_fields=extra_fields\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Save STAC item per cycle\n",
    "    json_filename = f\"sentinel-3{props.get(\"platform_serial_identifier\").lower()}-{props.get(\"zone\").lower()}-{cycle.lower()}.json\"\n",
    "    item.save_object(dest_href='examples/' + json_filename, include_self_link=False)\n",
    "    print(f\" Saved {json_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25640a5e-5e12-4604-b09a-009263a3ce67",
   "metadata": {},
   "source": [
    "### 3.1  Import documentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f50b311-f345-4862-866e-394606e29512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac\n",
    "from datetime import datetime\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "date_str = \"07/05/2025\"\n",
    "\n",
    "# Convert to ISO format string (YYYY-MM-DD)\n",
    "iso_like_str = datetime.strptime(date_str, \"%d/%m/%Y\").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Parse with isoparse and attach UTC timezone\n",
    "dt_utc = isoparse(iso_like_str).replace(tzinfo=timezone.utc)\n",
    "\n",
    "print(dt_utc.isoformat())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127296bc",
   "metadata": {},
   "source": [
    "### 3.2  Create STAC Item for the documentation associated to the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b5330-2380-488e-8a44-4dc09eea18e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic metadata\n",
    "doc_href = \"/d/S3_AMPLI_User_Handbook.pdf\"  # Relative or absolute href\n",
    "doc_title = \"Sentinel-3 Altimetry over Land Ice: AMPLI level-2 Products\"\n",
    "doc_description = \"User Handbook for Sentinel-3 Altimetry over Land Ice: AMPLI level-2 Products\"\n",
    "\n",
    "# Create STAC item\n",
    "item = pystac.Item(\n",
    "    id=\"sentinel-3-ampli-user-handbook\",\n",
    "    geometry=None,\n",
    "    bbox=None,\n",
    "    datetime=dt_utc,\n",
    "    properties={\n",
    "        \"title\": doc_title,\n",
    "        \"description\": doc_description,\n",
    "        \"reference\": \"CLS-ENV-MU-24-0389\",\n",
    "        \"issue_n\": dt_utc.isoformat()\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add asset for the PDF\n",
    "item.add_asset(\n",
    "    key=\"documentation\",\n",
    "    asset=pystac.Asset(\n",
    "        href=doc_href,\n",
    "        media_type=\"application/pdf\",\n",
    "        roles=[\"documentation\"],\n",
    "        title=doc_title\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save to file\n",
    "item.set_self_href(\"examples/sentinel-3-ampli-user-handbook.json\")\n",
    "item.save_object(include_self_link=False)\n",
    "\n",
    "print(\"ðŸ“„ STAC Item for documentation created: sentinel-3-ampli-user-handbook.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29107c8d",
   "metadata": {},
   "source": [
    "## 4. Generate valid STAC collection\n",
    "\n",
    "Once all the assets are processed, create the parent collection for all Items created in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8279ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = pystac.Collection.from_dict(\n",
    "\n",
    "{\n",
    "  \"id\": \"sentinel3-ampli-ice-sheet-elevation\",\n",
    "  \"type\": \"Collection\",\n",
    "  \"links\": [\n",
    "  ],\n",
    "  \"title\": \"Sentinel-3 AMPLI Ice Sheet Elevation\",\n",
    "  \"extent\": {\n",
    "    \"spatial\": {\n",
    "      \"bbox\": [\n",
    "        [-180, -90, 180, 90]\n",
    "      ]\n",
    "    },\n",
    "    \"temporal\": {\n",
    "      \"interval\": [\n",
    "        [\n",
    "          \"2016-06-01T00:00:00Z\",\n",
    "          \"2024-05-09T00:00:00Z\"\n",
    "        ]\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"license\": \"CC-BY-4.0\",\n",
    "  \"summaries\": {\n",
    "    \"references\": [\n",
    "      \"https://doi.org/10.5194/egusphere-2024-1323\"\n",
    "    ],\n",
    "    \"institution\": [\n",
    "      \"CNES\"\n",
    "    ],\n",
    "    \"platform_name\": [\n",
    "      \"SENTINEL-3\"\n",
    "    ],\n",
    "    \"processor_name\": [\n",
    "      \"Altimeter data Modelling and Processing for Land Ice (AMPLI)\"\n",
    "    ],\n",
    "    \"operational_mode\": [\n",
    "      \"Earth Observation\"\n",
    "    ],\n",
    "    \"processing_level\": [\n",
    "      \"2\"\n",
    "    ],\n",
    "    \"processor_version\": [\n",
    "      \"v1.0\"\n",
    "    ],\n",
    "    \"altimeter_sensor_name\": [\n",
    "      \"SRAL\"\n",
    "    ]\n",
    "  },\n",
    "  \"description\": \"Ice sheet elevation estimated along the Sentinel-3 satellite track, as retrieved with the Altimeter data Modelling and Processing for Land Ice (AMPLI). The products cover Antarctica and Greenland.\",\n",
    "  \"stac_version\": \"1.1.0\"\n",
    "}\n",
    ")\n",
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e299244",
   "metadata": {},
   "source": [
    "### 4.1. Add items to collection\n",
    "Once the collection is created read all the items from disk and add the necassary links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf5c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for fpath in glob.glob('examples/*'):\n",
    "    collection.add_item(pystac.Item.from_file(fpath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db4163",
   "metadata": {},
   "source": [
    "### 4.2 Save the normalised collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1156ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the full self-contained collection\n",
    "collection.normalize_and_save(\n",
    "    root_href='../data/example_catalog_ampli/',\n",
    "    catalog_type=pystac.CatalogType.SELF_CONTAINED\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
